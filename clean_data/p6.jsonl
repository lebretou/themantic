{"speaker": "Interviewer", "text": "Alright, so I will start with something that's pretty abstract. So, when you hear the term multi-agent system, what does it mean to you? Like, what's your definition of it?"}
{"speaker": "Participant", "text": "Hello?"}
{"speaker": "Interviewer", "text": "Hello?"}
{"speaker": "Participant", "text": "Sorry, I think we lost traction for a while."}
{"speaker": "Interviewer", "text": "Okay, so what is your definition of a multi-agent system? Or, to be specific, an LLM-based multi-agent system?"}
{"speaker": "Participant", "text": "Okay. So, I understand there is an overload of definitions on agents, specifically. So, nowadays, especially in tech, in industry, people refer to agents as having the ability to make tool calls. You do web search, do, like, use one of the tools, which is different from... But we have been calling agents in HCI, like, dating back to, like, 20, 30 years ago. So, typically, in HCI, we have been calling agents as autonomous software or programs that do something automatically for the user. So, any kind of recommendation system can be seen as an agent. A lot of universities, specifically any of the automatic functionalities we do for the user, like suggesting data patterns, suggesting data operations, can be seen as agents. Now, of course, if we're just calling the tool call using the tool call definitions as an agent, then the multi-agent system would be... You just have multiple agents coordinated together. They each have, maybe they have their own unique tools to use, maybe they have the same tools to use, but then there are communications in the system, probably using chat, using text. And they'll automatically decide what kind of branches, logical branches, to go to. And I've been using LangGraph, so, you know, LangGraph is a typical library for building these kinds of systems. I've also used AutoGen. Before that, it's more conversation systems, not necessarily having tools. I think they have tool calls support now, but when I used it, I didn't use it for the tool calls. So yeah, that's my definition."}
{"speaker": "Interviewer", "text": "Alright, that was great. So, could you now tell me about one or two representative projects that have used multi-agent systems? You can start from the line graph one that I just mentioned."}
{"speaker": "Participant", "text": "Though, that project was a multi-agent system for tax analytics. So I built a system where the user enters a goal, like a text analytics goal. Say if they want to analyze customer comments and they have like 10,000 customer comments. Then when they analyze it, an agent will first decompose it into multiple steps of analysis methods and analysis tasks. And then each task will be conducted using another agent, because most of these tasks will be using prompts to complete, or they will generate code to complete those tasks. So I have one agent do the decomposition, multiple agents do all of the analysis tasks, and then one final agent to aggregate all the results back into something the user can understand."}
{"speaker": "Interviewer", "text": "I see. So there could be multiple agents in the middle doing different kinds of analytics."}
{"speaker": "Participant", "text": "Yes."}
{"speaker": "Interviewer", "text": "Okay. Yeah. And then, so… was this overall structure pretty intuitive to you in the beginning? Did you have to worry too much about the structure, or did you kind of tweak it?"}
{"speaker": "Participant", "text": "I think the overall structure has been clear to me from the very beginning. We have looked at typical text analytics pipelines or workflows, and I know how they work already. So I know there should be some processing, and then you run the analysis methods, and then you have post-processing to do. So the overall architecture has been clear to me from the beginning. But exactly how to implement those agents and how to connect them together is something we experimented a lot with. And of course, we encounter many technical issues, like how consistent and how reliable these agent responses are. It's always hard to control the agents in software like a typical pipeline."}
{"speaker": "Interviewer", "text": "Yup."}
{"speaker": "Participant", "text": "I notice the text provided consists only of the word \"program.\" with a period. There are no transcription errors, stutters, grammar errors, or spelling errors to correct in this minimal text.\n\nprogram."}
{"speaker": "Interviewer", "text": "Okay. Alright, we'll go into that in a bit. But before that, so did you also think… So given this task, did you think at the very beginning, did you think a multi-agent system is like the most optimal approach? Did you try to just use a single LLM? Single agent."}
{"speaker": "Participant", "text": "So, did I try to use a single one? I think I do, yes. So when I think it depends on what you mean by a single agent. Does it mean I put all the system prompts in it and I have all the tool codes in it, and then…"}
{"speaker": "Interviewer", "text": "Potentially, yeah, just in a single model with all the tools."}
{"speaker": "Participant", "text": "I don't think I've tried the final version that we have, but we have definitely tried some simpler ones. So, say I have a goal. I give it a few analysis tasks, not the full list that we have, and I ask it to write the code to connect the codes together to generate a response."}
{"speaker": "Interviewer", "text": "I see."}
{"speaker": "Participant", "text": "For the user, I think I knew from the beginning that it would fail. It's just an experiment to prove to the professor that it will fail. So of course, even today, I don't think a single agent could do an end-to-end analytic task if it's, you know, too complicated and involves multiple tool calls and everything."}
{"speaker": "Interviewer", "text": "Yeah. And just to clarify, what kind of texts will you be analyzing using the system, and could you give one or two examples of the analytic tasks that you'll do?"}
{"speaker": "Participant", "text": "Yeah. So the simplest one is, say, literature review, right? So if I give it a dataset of publications, maybe there's 10,000 articles in it, and ask it to tell me which, how many, like, how would you categorize the research topics in this field?"}
{"speaker": "Interviewer", "text": "Maybe there are 10, maybe there are more."}
{"speaker": "Participant", "text": "Apparently, this is a task that involves multiple NLP, or text analysis, methods."}
{"speaker": "Interviewer", "text": "Yep."}
{"speaker": "Participant", "text": "You need to do segmentation, clustering, topic modeling, keyword extraction, and then, of course, summarization. There are many ways to do this already, and with these multiple ways, there are parameters to set. I don't think it's something that a single agent can do, for sure."}
{"speaker": "Interviewer", "text": "For sure. And then, okay, so you mentioned that communication between agents was also, like, one of the challenges that you guys had. Yeah. Could you elaborate on that?"}
{"speaker": "Participant", "text": "So in this project, in this system, we don't specifically encounter issues with context management. I don't know what you mean by context management, but this is not an issue for us. I mean, I can talk about it in my other project, but in this project, it's more about decomposition and connecting agents together. \n\nActually, the decomposer agent—so first of all, we have a decomposer agent, right? And we have execution agents. We even have an evaluation agent. And then we have to use or come up with our own DSL, or Domain Specific Language, in a JSON format, because, you know, that's how it's best to communicate between agents. The decomposer agent outputs some result in the DSL we have, and then the execution agent takes it and outputs something else, and then the evaluation agent does another thing. So this DSL is something we experimented with a lot—how to design this DSL, how to make everything robust, how to do error correction or output checks, consistency checks, stuff like that. \n\nAnother thing is text analysis methods. There's a very long list to pick from. And so sometimes we still have issues. By the time we finish the project, we still have issues with agents sometimes picking the wrong methods or not the right ones."}
{"speaker": "Interviewer", "text": "True."}
{"speaker": "Participant", "text": "The full list of methods that we need."}
{"speaker": "Interviewer", "text": "Right."}
{"speaker": "Participant", "text": "Another very specific to text analytics issue that we have is the results are chained between the execution pipeline. Say we start with an article that's, like, free from unstructured text."}
{"speaker": "Interviewer", "text": "We."}
{"speaker": "Participant", "text": "Say, do a summarization of it. And then we also do a keyword extraction from the text. So now we have this branched out output—one is the summarization, one is the keyword—and any subsequent tests that follow after this too can choose to operate on the summarization, or the keywords, or the original article. So there are three possible inputs that a subsequent task can take. And we need a way to specify that dynamically, because the outputs are dynamically generated."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "And so, I guess one general issue we have is that we're generating a data pipeline that's dynamic. We need a system that supports this dynamic generation and dynamic connection of the pipeline, which is quite hard. And we have to, of course, limit it to text analytics to make this thing possible. I can't imagine if we want to support every task. I don't think, at least for our scale, maybe if you have a multi-billion dollar company you can do that, but not for us."}
{"speaker": "Interviewer", "text": "So, like, how did you eventually reach that dynamic input? Was it more engineering, or was it those system prompts that…"}
{"speaker": "Participant", "text": "I think it's both. So, first, we have to come up with a new conceptual framework to do this. So, basically, in LangGraph, we formulate every task as having a map-reduce chain. So, basically, the input of a task for any LangGraph node is first mapped to any input that we want it to be. Let's say the input has all three fields, right? Original article, summary, and keyword. We do a map to pick the input we want, maybe multiple ones, and then we have some actual analysis method note or chain that takes this input, executes a function, and it generates an output. Then we have a reduce step that aggregates the output into another format that we want it to be. Okay. Every node is in this structure, and using the structure, we're able to support all the analysis methods we want to support while ensuring that these things can be dynamically connected. So that's both a conceptual thing, a research thing, and an engineering thing, because this is not a typical way to use LangGraph."}
{"speaker": "Interviewer", "text": "We're actually generating graph nodes on the fly."}
{"speaker": "Participant", "text": "And generating the functions that the agent node needs to execute on the fly, too. So that's engineering effort. So, I guess it's both, yeah."}
{"speaker": "Interviewer", "text": "I see. And then, okay. So a lot of my other interviews mentioned that writing system prompts was another challenge when they were trying to build a multi-agent system. Yeah, because it's a lot of trial and error. You kind of just have an initial prompt, and then you run the pipeline multiple times, just waiting for unexpected behaviors. And then, if you see them, you would just go back and try to include that unexpected behavior into the system prompt. And, for example, like \"do not do this, do not do that.\""}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "Did you have similar issues?"}
{"speaker": "Participant", "text": "Yes, so we have the exact issue too, but my collaborator was mainly responsible for writing the system prompts. I myself know how to write the system prompts; it's just, you know, we delegate it to my collaborator. But the system prompt that we ended up with is very long. I think it's like 50 to 100 lines, even more, and I saw him having to do exactly like you said—do not do this—or he has to give a lot of future examples in the prompt."}
{"speaker": "Interviewer", "text": "Yep."}
{"speaker": "Participant", "text": "So, and that's just one system prompt, because we need a system prompt for every analysis method that we have, and we have a list of analysis methods. We also need system prompts for all the agents—the composer, the evaluation agents. Those are also very hard to craft a prompt for. I think we eventually ended up with, because we have... we're at the paper, and then in the appendix, we have all the system prompts. We have at least 20 to 30 different system prompts in the system. And they're all very long and very hard to write. We spend a lot of time on trial and error with this. I don't think there's a... And I think that's also why we have to limit it to text analytics, is because the prompts are very specifically written for text analytics, and it will not generalize to other kinds of tasks. And I think my collaborators spent a lot of time trial and error on this, and I think it's this effort of trial and error that got us to coming up with that conceptual framework that we ended up with."}
{"speaker": "Interviewer", "text": "That eventually we are... at least make it..."}
{"speaker": "Participant", "text": "Feasible to do, and we don't, like, spiral down into chaos."}
{"speaker": "Interviewer", "text": "Okay, sorry. Could you re-explain the conceptual framework? I think I was a little lost. You talked about wrapping the inputs and outputs."}
{"speaker": "Participant", "text": "Yes, so that's very specific to text analytics, for sure, but essentially, it's a framework to handle the input-output format between the analysis methods we're going to run. So the first step is summarization, the second step is sentiment analysis, and then topic modeling, and then keyword extraction, stuff like that. All of these steps have a specific input and output format that it needs, and they're all generated dynamically. So first, we have to generate these—I mean, we can have these steps conceptually in general, generated—but we're actually generating the parameters of each function."}
{"speaker": "Interviewer", "text": "We have to generate it in SQL."}
{"speaker": "Participant", "text": "Or sequentially, because, say, the second step is sentiment analysis, I need to know the input of the sentiment analysis, right? And the input could be generated by the first step. So I need to generate the output of the first step first, and then use that as the input for the second step. So we're kind of filling in these function parameters. And of course, the function body itself sometimes needs to be generated too."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "But then everything, when everything is dynamically generated, first, the output format needs to be exactly what we want it to be. That's why we have the DSL, to make sure of that. We can check the type errors and stuff like that. And we need that conceptual framework to formulate every node in this chain consistently, because we have to generate something, and if we don't have a structure, we don't know what we're generating, and it's going to have type issues, or syntax issues, or any kind of issues that you could have in generating code. So we have to have that dynamic conceptual framework, and the agent is essentially filling in the templates."}
{"speaker": "Interviewer", "text": "I see."}
{"speaker": "Participant", "text": "of the conceptual framework. That makes it much easier to do."}
{"speaker": "Interviewer", "text": "I see. Could you also talk a little bit about the debugging process? Like, you mentioned having all these errors. Did you… I know LangGraph has this. It's called… I think it's called LangSmith Studio."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "For you to monitor."}
{"speaker": "Participant", "text": "It's just..."}
{"speaker": "Interviewer", "text": "Did you use something like that, or did you have your own methods?"}
{"speaker": "Participant", "text": "When we developed the project, I think LLaMA was still under development, or at least not exactly what we wanted. So we did not use it. So the debugging has been purely traditional machine learning or Python. And debugging?"}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "It's a lot of printing. We're looking at it."}
{"speaker": "Interviewer", "text": "The intermediate outputs."}
{"speaker": "Participant", "text": "Yes."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "I was using Jupyter Notebook, of course, to do the debugging."}
{"speaker": "Interviewer", "text": "Okay. Because that way I can save the states and, you know, execute one cell."}
{"speaker": "Participant", "text": "But that's all that we have. I think LangGraph has some built-in debugging support. For, I don't know if they're called Debug Explorer, just memory handling or state handling and stuff. But I would say the whole debugging is just Python."}
{"speaker": "Interviewer", "text": "Okay, I see. And then you talked about your agent roles—you have a decomposer and then a bunch of execution agents, and then some evaluation agent. What was... like, which agent failed the most according to your experience?"}
{"speaker": "Participant", "text": "Domain felt the most. I mean, the most. Of course, it's the execution agent. So the decomposer agent basically just does text generation, as long as the generated text fits the upload format, and we want it—it's not a complicated format—it's good, it's less likely to fail. The execution agent is where it generates code and connects functions together. So the logic has to be... it cannot be wrong. Like, none of the logic can be wrong, and whenever there's something wrong in it, it's going to fail. And I think eventually, we have to engage the user to surface the errors and help them fix the errors, because the ultimate system that we have is not guaranteed to generate, to always generate a working pipeline. It's like 80% of the time, maybe it can generate a working pipeline. But there's always edge cases where it just doesn't pick the right parameter, or it doesn't pick the right method altogether. And something has to be done to intervene and fix the issues. The evaluator agents are actually... they should be equally complicated with the execution agent, but we did not go too deep into the evaluator agent, so we intentionally let it be simple. It just runs self-evaluation judges on the execution results, so that's... that turned out to be much easier and much less likely to fail, to have technical issues to fail. Of course, it has some compromises in the evaluation rigorousness, but technically the system, you know, is at least working. We can run the user study on it, at least. And so, in general, I think whenever... one of the things we're generating is prompts too. So for all of the evaluation methods, we're generating prompts for that evaluation criteria, and..."}
{"speaker": "Interviewer", "text": "Correct."}
{"speaker": "Participant", "text": "So, whenever we're generating prompts, it's much like it's much, much less likely to fail. Because the LMs are already trained—I guess OpenAI tuned their model to follow the JSON output quite well—so as long as we have that defined, at least there's not going to be syntax errors, for sure. You can't have syntax errors in the prompts, or you won't have format issues because, you know, it follows the format. Whereas in code generation, it can generate syntax errors, for sure. It can generate the wrong parameter that doesn't exist. In our conceptual framework, a node needs to pick its input key, which is the output of a previous node, and sometimes it can pick the wrong key. And that's the major issue of failure. So that's most likely to happen in execution agents."}
{"speaker": "Interviewer", "text": "That's it. So you talked about wanting to have a reliable pipeline in the end. And then, what made you decide that this is viable enough to put in a paper?"}
{"speaker": "Participant", "text": "It's... to be honest, it's because the deadline is approaching. That's about the system."}
{"speaker": "Interviewer", "text": "We have tried…"}
{"speaker": "Participant", "text": "And we have actually tried all the methods that we can think of to improve the reliability of the system."}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "I think the decision for cutting off development was partly influenced by the deadline, but also because we think it's enough to run a user study. And we're able to get reasonable or interesting insights from the user study, even though some corner cases might not be supported. We'll just try to not let that happen in the user study, which is focused on the human-centered factors of the teaching systems, not just the technical contribution. And so, if we can get something interesting from this study, that's enough. Of course, we'll have to explain the reliability issues in the paper, and that's enough for us."}
{"speaker": "Interviewer", "text": "Okay. And then, so you mentioned that you used LangGraph, and I want to ask if there are any features that you think would be great to have or add to LangGraph. But of course, like you guys eventually developed a framework to make it more suited for your project. But are there any new features that you think would be great to have to speed up either development or create more reliable pipelines?"}
{"speaker": "Participant", "text": "I think... So, it has been half a year since I used LangGraph. I don't know what new features they've added to the library, but just from my past experience, I don't remember, but I think there are some... like, LangGraph is supposed to support all the possible logical branches that you could have with nodes. I think I don't remember, but maybe there's some logic that is very hard to express using LangGraph specifications. And then, typically, right, you would add... I think LangGraph was not built for this, but in my case, I was dynamically generating the nodes. And that's not something that LangGraph natively supports. I think that could be supported, because I imagine there's going to be, like, really complex cases where you, like, the developer needs to generate a new node on the fly. It cannot all be covered with their existing development effort. And then, LangGraph is mostly for the evaluation part. Most of LangGraph has support for, like, checking the formats, like, throwing errors for it. I think that's what they intended to do. But for, I think, many cases, especially seeing that agents are so unreliable, it's good if they have some native support for evaluation in general. I want to... it's basically, most of the agents are just generating text, right? Yeah. So you could have evaluations based on these text generation methods. There are existing validation methods to do this. I don't think they have support for any of them, so we have to do it ourselves. I think the other ones are to construct a graph not using code, so I think they have support for this. At least AutoGene has the support for this. I don't know if LangGraph has it. It shouldn't be too hard to do this."}
{"speaker": "Interviewer", "text": "Not using code, so using natural language."}
{"speaker": "Participant", "text": "Oh no, using... like, why?"}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "Yeah, so AutoGen has AutoGen Studio to do this. I don't know if I have a LangGraph Studio or something."}
{"speaker": "Interviewer", "text": "They actually do, but I don't think they're the best."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "There are many different UIs out there, you know, like those kinds."}
{"speaker": "Participant", "text": "Yeah. And so, once you have the UI, if they have a really good UI, and then LangGraph has this human-in-the-loop method, like, for interrupts. Right now, the interrupts is just, you know, having a breakpoint, and then some human input, like, because they're essentially a library—a Python library. So, if you have a UI, and if they have support for human in the loop on the UI, it can be for developers, or it can be something that the developer can release into a full system, a customer-facing system, and the customer can intervene in the loop. That would be nice, because right now, we have to do it all ourselves."}
{"speaker": "Interviewer", "text": "Hmm, I see. Okay. And then that was a lot of information. I think I'll, I won't let you describe it in as much detail, but you said that you also worked on other projects that used a multi-agent system. Just like, a couple of sentences. What was the goal of the system, and then just a high-level structure of the system architecture."}
{"speaker": "Participant", "text": "So, an ongoing system we're building is for multi-agent debate, or multi-agent dialogue, and we're building a system to see where the opportunities for human intervention are, and how we can support that human intervention. I've also mentioned another project that involves contacts management, but that's not exactly a multi-agent system. That's more like a single-agent system that has RAG, has tool calls... not tool calls, it's just a... it's just a RAG agent."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "So, yeah."}
{"speaker": "Interviewer", "text": "I see. So you actually worked on quite many projects that used multi-agent systems. So, if you have to generalize, for what type of tasks or problems do you think a multi-agent system is the optimal approach?"}
{"speaker": "Participant", "text": "I think it's… So, first, it's always because the LLM's capabilities are always improving. We now even have reasoning models. When I did the multi-agent system, we didn't have reasoning models. So, I think some of the multi-agent systems can now be replaced by a reasoning model—a reasoning agent, for sure. So we have to always look at the capability of a single agent to decide if we need multiple agents. It's only when the use case is so complex that a single agent cannot handle it that you employ a multi-agent system to do this. Because when you have multiple agents, there's always more technical complexity, more… or less transparency. It's harder to control. But there's also another case: if the problem you're dealing with is well-defined, or if you can find a good theoretical framework or structure underlying it, then you can build a multi-agent system that roughly follows that structure. So, yeah. Now I remind you of one of the past projects. It's not an agent, but it's a mental health chatbot. So, as you can imagine, mental health has, you know, a bunch of guidelines and principles for that. And so that's what I meant by very well-defined guidelines and principles. You can easily build a multi-agent system following that guideline, or you can transfer that guideline into a multi-agent system. And theoretically, right, this multi-agent system should perform more rigorously compared to a single agent, because single agents always have context issues—it might not always follow the steps you give it, but if you…"}
{"speaker": "Interviewer", "text": "I don't have enough text to correct. The input \"you have.\" appears to be a fragment rather than a complete transcription. Could you please provide the full interview text that needs to be corrected?"}
{"speaker": "Participant", "text": "A multi-agent system, you can force it to follow the structure you want. Because every agent is just one step in this flow, then you just need to control the connection of the nodes, and you can guarantee you have the structure you want. So that's good. And then, there's also other cases where you want to have a multi-agent dialogue, where you want to have a diversity of opinion, or you want to have a diversity of basically, you want diversity. Then you can have different role-playing agents. Each agent plays a role. Say you're making a policymaker, and you're dealing with multiple stakeholders in that policy. You can have a typical resident, you can have an insurance company, you can have private companies, private sector companies, public sector companies, and you can have each of them represented by an agent that then engages in a debate or a conversation or a dialogue, and then try to get a more diverse outcome of it. That's also one thing I can think of to use multi-agent systems for. Let's see, I think that's it for now. Yeah, I think so."}
{"speaker": "Interviewer", "text": "Also, very comprehensive response. And okay, that was actually the last question I have. We can go ahead and stop the recording."}
{"speaker": "Participant", "text": "Great."}
