{"speaker": "Interviewer", "text": "Duncan's… Okay… Okay, I guess we can go ahead and start. So, I will start with some, more, like, abstract questions. So, like, when you hear the word, multi-agent system, like, what does it mean? For example, like, how is it different from just a single agent or a single LLM?"}
{"speaker": "Participant", "text": "So, thing… when we talk about it's not like… it shouldn't be, like, a one answer, why it is different. But, so, first of all, when we talk about difference, so, multi-agent, and when we talk about agent, we say it should be LLM, but multi-agent is not a… there will be multiple agents, first of all, when we break down the word, but if we talk about a product, let's say a particular X use case, there are 10 agents used, and one agent is a manager agent or orchestration agent, but that doesn't mean the remaining 10 agents will have LLM. First of all, they are differentiated with it. Agentic workflow is mainly because one agent is involved, and then more in 99% of cases, only a single agentic workflow, LLM is there, but in multiple agentic workflow, it doesn't mean LLM will be involved. And we can take a RAC pipeline. RAG is a basic RAC pipeline is a use case of a single agent workflow, but multiple agents is not about just LLM. It's about end-to-end flow with LLM, how… Each entity should work, and the main role in that is the orchestration agent, because when we talk about the agent, it's not just a sequential flow from start to end. Multi-agent is basically not from start to end, or independent agents, if we talk about a space of a multiple multi-agent workflow, multiple agents are there. not connected with each other. It's the job of the orchestrator agent to identify which agent to go, and if we create a workflow, like A, B, C, D, E, so it's one workflow of organization, but if use case changes without any code change. every time is not… it doesn't going to be ABCD, it's DCBA, and, like, this agentic workflow will change. So, we can say it's no… so it differs from agentic workflow. Single agent workflow is, we will always going to change the pattern of how each agent going to interact."}
{"speaker": "Interviewer", "text": "I see, I see. It's… it's interesting you said that, like, multi-agent, is not, like, a… like, a linear, sequential process. I feel like… I feel like sometimes they can't, right? Like, Sometimes it's just, like, multiple agents each have different, tool calls, or, like, access to different tools. But then the whole pipeline is still, like, linear."}
{"speaker": "Participant", "text": "Yeah, the pipeline is linear, but depending… so… so it's not like each agent will be called. Every time. That is also… based on the user input, sometimes this agent will be needed, and sometimes not. So, I will take an example where, suppose a prompt is used, LLM. giving a response. So, for a particular case, we will get a correct response, so it will pass through the pipeline. So sometimes we do not get a correct response. So, it will go to the fallback, and sometimes if in fallback, we write, should update the prompt. Based on route feedback, prompt updation will occur, and this cycle will go over. So, like this, the flow changes."}
{"speaker": "Interviewer", "text": "Yeah, I see, I see. Alright, okay. I'll go to the next question. So, I think you already talked a little bit about it, in your, like, the Google form that you took, but, like, what is your role and experience in, developing or using, multi-agent system?"}
{"speaker": "Participant", "text": "So, basically… so you're talking about my academic, or before, also?"}
{"speaker": "Interviewer", "text": "Oh, anything, anything. Just any."}
{"speaker": "Participant", "text": "So, I'm an international student here, first of all. So, I did my undergraduation in computer science, now I'm doing my master's."}
{"speaker": "Interviewer", "text": "So."}
{"speaker": "Participant", "text": "I graduated in 2022, and after that, for 3 years, I've worked as a… as a LLM engineer in Morgan Stanley. So there, first, my experience starts from there, where we were… I have worked on agentic workflows. So, whereas a financial firm, they do not have structured data, they have unstructured data, and unstructured, I mean just PDFs. So, no Python code, you can detect the pattern to read a PDF and get a structured data. We need an agentic AI system there. So, initially, we started with single prompt, that is LLM, then we expanded to Agent Workflow Single Agent, then we expanded to multi-prompt, multi-agent. So how there we have worked, we… so each… each data source is different, each data type is different. So it's, like, we can say it's, like, an infinite possibility of how much data we will get. So, that part is done by a manual analyst. So, it writes a document. So, what my agent… multi-agency workflow is. first agent is reading the data. There is another agent. When we read the data, we get the page, so where… where we use vector embeddings to get… because documents are more than 100 pages document. So, we use a… we use embeddings to get correct pages. Once we get the correct pages, so suppose we have to extract 10 data. So, as I can say, there are an infinite possibilities of data, so we can't write prompts for each data. And we can't write a generic prompt. Bird has manual analyst, they prepared a documentation, which is, you know, so I have an agent that read that documentation and create prompt for me. So I'm using LLM to create prompt itself. And then use that prompt to extract that data that I want. Then in other regions that are doing validation, data storage, normal process. And so that's what I have worked for in Mormon's journey, and after coming to, you know, Maryland. So at UMD, I have been worked as a research scientist in iSchool, research assistant at iSchool. Where it's under Cody Button, where mainly I'm using LLM in agility workflow for crisis fact. There is a project going on under Universal Man. So, it's a dataset that they have created, which is a dataset of social data science. Which involve crisis-related data. So, it's already there for textual data. I'm working with LLMs in Agentic workflow to get data for images and other multimodalities. And along with it, I'm also working with Professor Tiani Ro, where we have just completed our research, which is design chart, where we are using LLM Agentic workflow to fine-tune a model So… We are doing LoRa fine-tuning and full fine-tuning, where we have created a dataset using Shark5 dataset, where a basic goal is to create a JSON with design choices. With just reading the CSV, our fine-tuned LLM can give a particular industry-level, specific industry-level data."}
{"speaker": "Interviewer", "text": "I see. So, for those, projects that you just, you just described, like, what kind of, framework did you use? Like, lane chain, lane graph?"}
{"speaker": "Participant", "text": "Yeah, Langchen and Langorov."}
{"speaker": "Interviewer", "text": "Then channeling graph, okay."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "I see."}
{"speaker": "Participant", "text": "Oh, I'm… but I'm in a recent hackathon project, I'm exploring towards MCP and Google ADK framework also."}
{"speaker": "Interviewer", "text": "I said, okay. Yeah, it seems like, LaneGraph is still… The more popular choices."}
{"speaker": "Participant", "text": "More popular choice, yeah."}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "It's derived from LanChain, and LanChain… because Google ADKs, it's coming, like, now only, MCP, Google ADK. But previously, from the start, is the LanChain that have started to develop everything."}
{"speaker": "Interviewer", "text": "Yeah. Have you ever had a chance to use one of those, like. like, more, like, visual tools, the ones with, like, nodes as, agents, and then you can draw links."}
{"speaker": "Participant", "text": "Cool. Lyco…"}
{"speaker": "Interviewer", "text": "Like, there's… there's this tool called… I guess I can share my screen, show you real quick."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "Sure. Okay. So… I think, people have, like, came out with… can you see my screen?"}
{"speaker": "Participant", "text": "Yeah, yeah, I can see."}
{"speaker": "Interviewer", "text": "Yeah, people came out with, like, this kind of interface, but I guess it's not really, it doesn't really fit your tasks, because they're… they're more for, like, How do I make this bigger? it's more for, like, like, daily tasks, so they have, like, some type of, trigger, that, like. Say whenever you get a Gmail, a new email, it triggers the pipeline, and then it do something."}
{"speaker": "Participant", "text": "So, so as you're talking about visualization and notes, I haven't particularly used any, but I've used Neo4J."}
{"speaker": "Interviewer", "text": "Oh, what is it called?"}
{"speaker": "Participant", "text": "It's called NeoForge. It's a graphical database. So, basically, agent… it's… when it was developed, it's not developed for agent workflow, it's a graphical entity database, where it's… we do normal SQL-like queries. But later on, they integrated agents in that workflow."}
{"speaker": "Interviewer", "text": "Oh, okay."}
{"speaker": "Participant", "text": "And it's integrated with… and it's, data sources integration with anything, even Google Cloud, AWS, HDR, you can directly connect your cloud environment. But it's not an open source, and it's for commercial use. So, basically, when I cannot take it on long-term, when I do, like, some small class projects or hackathons, I use that. I'll basically create an account and get GCP free credits for one month."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "End user, yeah."}
{"speaker": "Interviewer", "text": "Okay, and I think you, Okay, so for, like, let's say for the first project that you talked about, the one that, like, structures data."}
{"speaker": "Participant", "text": "Like…"}
{"speaker": "Interviewer", "text": "Is the system… perhaps, like, you're going to, like, reuse the systems, like, over and over, right? Whenever there's new data that comes in? Or is it pretty automatic? It just triggers itself?"}
{"speaker": "Participant", "text": "Yes, it automatically triggers itself, because we have a collaboration with Azure and JCP, so there is a data lake that we have stored, so whenever new data comes, we have created a PubSub request. So, PubSub is basically publisher and subscriber. Whenever any data comes, we get a trigger request, and our pipeline will start."}
{"speaker": "Interviewer", "text": "Okay. And then."}
{"speaker": "Participant", "text": "And one more point, we also target the volume also, because we do not do one-to-one processing, we do processing on a bunch of volume, so we are based on fiscal year and the quarter we are, because in financial terms, quarter, the data volume changes. So, we target, like, at which data voluma trigger should trigger."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "Oops."}
{"speaker": "Interviewer", "text": "I see. And then you said that, like, the reason why you had LLM is because, the… the data was… In PDF, right? And you kind of need…"}
{"speaker": "Participant", "text": "Data was in PDF, and only PDF is not the case, because if it's in PDF and a pattern is structured, we can use normal reject expression or Pythonic code to detect that pattern in a code format and get the data. But in PDF, things changes. Companies… because companies who are writing the reports, they are not AI system, or not any system was giving the structure. They were humans who are writing those reports. And your money may fall in."}
{"speaker": "Interviewer", "text": "And handwriting, okay."}
{"speaker": "Participant", "text": "It's not handwriting, it's like a Word document."}
{"speaker": "Interviewer", "text": "Oh, okay."}
{"speaker": "Participant", "text": "document, it's like, it's not handwriting, but it's not different than handwriting. They're writing a report, like, in a notes document using a computer, but those are human analysts. They won't follow the same pattern. Companies' pattern changes, report types changes, so the uncertainty in there is too much."}
{"speaker": "Interviewer", "text": "Okay, I see, I see. And it seems like, just given a task, like, a pipeline is probably the best choice, to automate, like, different parts."}
{"speaker": "Participant", "text": "Yes."}
{"speaker": "Interviewer", "text": "Okay. Alright, I'll jump to, the next, next question. So, again, let's still talk about, the data project. Could you walk me through from, like. when you had the initial idea to, when you have the concrete, multi-agent system architecture set up, so, like, what were, like, the first couple things that you decided? Like, the roles of the agents, or, Did you, like, sketch out the architecture?"}
{"speaker": "Participant", "text": "Yeah, so as I said, first of all, our initial goal was not to go directly towards the multi-agent, because as I was a professional LLM engineer there, I've worked for 3 years. So, initial, we are… there was a Pythonic and manual analyst available. So, first, we eliminated with direct prompting. So, we have just write a Pythonic script, and we replace the prompting. replace the manual part with just prompting with one algorithm. Then go on to secure single agent workflow. Then when we go on to the multi-agenting workflow, so firstly is our PubSub part we have added, where we are getting the volume of data, and when to trigger our pipeline. And as soon as we trigger, so the second agent we added is to read the data. That's the PDF. And then when we read the PDF, we got to know if we pass entire PDF, our token limit will shoot up."}
{"speaker": "Interviewer", "text": "Right."}
{"speaker": "Participant", "text": "Because at a firm, cost is also an important factor. So, then what we done? We foresee the vector database. So, then we got to know the Mistral database. Why Mr? Because Mistral has the very, very scalable DB when we scale it in… with the help of Google Cloud. And it's natural language pairing is very best, as we tested out experiments. So, then what we done? We added an agent that, first of all, that will take these new documents. new doc… if we get any new documents and old documents, there are two criteria also. If we get a new document, we take the document first, include it in vector database of Mr. DB, then… then there is a… we have a data… other database, where what kind of data we need to extract. From a document that changes from year to year, quarter to quarter. And companies to company. So, based on that, we got a company name, we match it to the database with which fiscal year we are processing, and which quarter we are processing. So, we got, like, these are, like, X amount of doc, data points, data points we need to extract. So, first of all, as we got this data point, we get a data definition. So, we use, then, another agent that used this data definition. And, query on the vector database to get the page numbers. Then we have got a shrunken size, shrinking size of a PDF, that in this PDF data will be available. We need to query only this PDF. So one agent will return these PDF numbers. Then, there will be another agent which will again use these data point names, X names we have got, and there is a data rules document we have. That will… each data point which have a rule, like what kind of… basically instructions to extract the data. So, we will use that and pass it to that rules document. This is an LLM agent. what it will do, LLM agent, will use this rule document, and with X this amount of data sources, and create prompt for us. Okay. For data extraction. And at the end, it will be a JSON format in which we will get the data. Then there is an LLM executor agent who will take this prompt, and take these pages that we have get, and use this prompt, and in the input, we'll take only the shink and size document pages, and extract the data. And as we got the data, then there are other 3-4 agents that will take this data, process it, and then validate it, and everything is correct, then push it into the database. So, this process is also, like, 4 to 5 regions, and at the end, there was an orchestration again. And we also have validation, you know, to check if we are getting a correct format of data or not."}
{"speaker": "Interviewer", "text": "Okay, so, like, so when you decide the, for example, like, the system prompt for all of those agents. Did you have to, like, trial and error, or…"}
{"speaker": "Participant", "text": "Yes, we have to trial and error. We have done trial and error making this timeline, like, minimum 6 to… 6 months to 1 year. And how we have assessed the accuracy, because as a financial firm, we have historical data available. So first, we have tested our pipeline with historical data. So, in that data, we have ground truth available for 10 years minimum. So we have used that data to test our pipeline. Then we have made it run production."}
{"speaker": "Interviewer", "text": "Okay. Did it, like, eventually reach… Oh, like, what was the accuracy in the end? like, a hundred… probably not 100%, right? Or, I always worked."}
{"speaker": "Participant", "text": "It's more than 90, and that's our aim."}
{"speaker": "Interviewer", "text": "More than I need."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "Okay, and did you look into those, like. less than 10%? Like, what was the errors?"}
{"speaker": "Participant", "text": "So, when we looked around that, it's basically the data formatting errors are there. When LLM couldn't able to give us the proper structure of the data, that's where that data is thrown out. Because when we talk about LLM and data extraction, it's hardly that LLM will fail. Because that LLM doesn't have a space to hallucinate. Because we are giving the LLM the definition, we are giving the LLM on… in this page, we have the data. Only you need to do is, on a particular data point, you need to map it. This data is for this. Okay. So here, we are… LLM does not have the space to think too much."}
{"speaker": "Interviewer", "text": "I see. So, because it's mostly just, like, text-related tasks. And you guys have very specific, definitions."}
{"speaker": "Participant", "text": "Yes."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "So, because the definitions, it's not only defines, it's a set of rules."}
{"speaker": "Interviewer", "text": "It's a flood."}
{"speaker": "Participant", "text": "You know, this step, this step."}
{"speaker": "Interviewer", "text": "I see. And then, could you also talk about, like, how did you define, or… eventually come up with the context and, for example, like, memory management of… or the entire orchestration between agents. Because I know, this, this project used Lane Graph, right? Lane chain."}
{"speaker": "Participant", "text": "Yes, yeah, thank you."}
{"speaker": "Interviewer", "text": "I know that Langraph has, like, their states. what's called, the state as their memory. So basically, like, each agent just, either retrieve or, like, update the states. That's, like, the shared… context."}
{"speaker": "Participant", "text": "Okay. So, first of all, I have used, like, Okay. Okay, so first of all, how I can say memory optimization we have done? Yeah, so first of all, we haven't, focused… We haven't focused much on how we should do the memory allocation, because we have used GCP, so when we talk about scaling, GCP automatically does that all part, because our pipeline, everything was done by GCP, so orchestration is not an issue for us."}
{"speaker": "Interviewer", "text": "Yeah, yeah."}
{"speaker": "Participant", "text": "We haven't… but we are focused on tokens, so our cost should be minimized."}
{"speaker": "Interviewer", "text": "Okay, yeah, that's fine, it's not always relevant. Okay. And then… I think… Okay, I'm gonna ask this question. So, like, before you go into, like, actually, writing the code, when you're still, like, trying to design, and maybe… Think about, like, the overall architecture, what, like, what was the hardest part for you? Or what was, like, the biggest challenge?"}
{"speaker": "Participant", "text": "The biggest challenge was the orchestration part, like, how this agent should work together. And the main part was… because the… this is the different thing that we are doing. We are not creating the problem, we are telling LLM itself to create the problem. That was the hard challenge for us."}
{"speaker": "Interviewer", "text": "And to create a system from for that, we have to do, like, many trial and errors. Trial and errors, okay."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "I see. Did you also have, like, the rules for the… Like, the prompt writer."}
{"speaker": "Participant", "text": "Yes, so that's what I'm telling about the system prompt. So there we have mentioned many rules when we read the document and create a prompt, so we shouldn't get a destination and all. So that's why… We have provided there many instructions that you should read only from this document to create a prompt. And prompt, you should give an output format of the prompt that you have created. So, like that, we have specified many instructions."}
{"speaker": "Interviewer", "text": "Okay, I see. Yeah. And also, just a side note."}
{"speaker": "Participant", "text": "So…"}
{"speaker": "Interviewer", "text": "Actually, there has been, I think, 12 people signed up, and I think your, your project, or your experience is, like, by far the most, sophisticated. People, people, I can tell you some of the other responses. They're mostly, like. a pipeline for summarizing, like, research paper. Things like that."}
{"speaker": "Participant", "text": "Okay, okay, okay."}
{"speaker": "Interviewer", "text": "Yeah, and okay, so… I want to now talk about, a little bit, on, like, debugging. So… First of all, can you tell me how, like, you usually interact with or monitor the system once it's up and running? And, how do you, like, how do you verify the result? I guess you talked about it a little bit, you have ground truth. But let's say… Did you have, like, a monitoring interface or any methods that you used to monitor the results?"}
{"speaker": "Participant", "text": "So, first of all, as I said, we have ground truth. So, initial debugging, we use the ground truth, but that is for that type of debugging is for end result. But before that, we have… we have used Google Cloud Logging, so as our system is complicated, we can't just, if we use a normal print statement, and we say, your error, try catch, and say, your error has occurred. We are never going to find out at which module we have faced that error. So that's why we have Google Cloud Logging. Why? Because using the Google Cloud Logging, it will give us the exact location, basically exact module where error has been occurred, then we can use a live Google Cloud debugger to get all the state variables at that point of logging, and debug it. So yeah, so that's the… this is the two kinds of law debugging we have done. One is the… using the ground truth to get the metric-level debugging, and other is the programmatical-level debug."}
{"speaker": "Interviewer", "text": "Okay. So for the Google Cloud, like, debugging, usually, like, what kind of errors does it throw out? Like, compiling errors, or… Like."}
{"speaker": "Participant", "text": "It's, it's… sometimes it was so resource errors, you're not getting the model LLM, you're not getting the correct LLM, API key expired, or system variable changed. This all, it's not syntact. Sometimes we got syntactical error, but that's a rarely. More of them is our runtime memory error."}
{"speaker": "Interviewer", "text": "I see. Okay. And then… So for the… okay, more questions about the Google Cloud. So. Because I haven't had a chance to look at it, like, what kind of… system is that? Is there, like, like, a dashboard for you to monitor?"}
{"speaker": "Participant", "text": "Yeah, so Google Cloud Logging, there is a service, there is a kind of dashboard that gives us ability to monitor everything. And apart from the other services we use, it's just for deploying and running our server live. So it shouldn't be on a system, but actual server."}
{"speaker": "Interviewer", "text": "Okay. And then, like, what type of information will you see? Like, like, latency? Or like…"}
{"speaker": "Participant", "text": "S latency, if a particular we have gotten an error result also, throughput of error, the frequency, what we are getting, the error of data, both error occurring where data are… are we getting the data. What are the inputs, what are the outputs, data getting stored at the database, then you're getting the throughput of that also. So, like that, yeah."}
{"speaker": "Interviewer", "text": "Okay. Okay. And then, alright, so the next… next question is gonna be a little bit abstract. Like, so, some people describe, their, like, relationship with AI systems, in terms of, like, how much they trust or rely on them. Do you feel like that's relevant?"}
{"speaker": "Participant", "text": "So, for my project, it was totally relevant. But, it's not like we are trusting AI. I'm using LNM to do a specific task, and I'm measuring it using my ground truth."}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "So it's just… there were two steps. It's not I'm trusting AI, it's not like I'm not trusting AI. I'm using my own metric to determine if I should trust this prompt or not."}
{"speaker": "Participant", "text": "And at a point where I get the best from Diamonds in there."}
{"speaker": "Interviewer", "text": "And you're using strategies to make it more reliable, or, like, consistent."}
{"speaker": "Participant", "text": "More consistent, yes."}
{"speaker": "Interviewer", "text": "Yeah. Okay. Okay, and, for the… the framework, the Google Cloud or, Langraph. Are there, are there any signals of, like, This is also a little bit abstract, but, like, signals of confidence, or, like, the uncertainty in the system."}
{"speaker": "Participant", "text": "So, I haven't found, like, the… any uncertainty at that time, but obviously there are… there are uncertainty in response output format, but in some cases, majorly, the LLM results are focusing strictly relying on the JSON format."}
{"speaker": "Interviewer", "text": "Oh, sometimes they don't strictly follow?"}
{"speaker": "Participant", "text": "Yeah, sometimes they didn't… they didn't follow."}
{"speaker": "Interviewer", "text": "Do you have a sense of, like, why that might be, if you have already defined."}
{"speaker": "Participant", "text": "It's because, you know, sometimes it's because they are not clearly able to understand the structure, so that is a part of uncertainty and hallucination. But mainly, I think that occurs because I am… sometimes… so that we have updated it later on. We are not… if we have too much of data, too much… many pages have been detected, then we are passing in multiple prompts. So, for that, they are minimized very much. So, it is the number of tokens you are passing. Okay. I think that's the answer for that."}
{"speaker": "Interviewer", "text": "Okay. Okay, and this is… this might not be true, but, like, have you ever encountered cases where… since you have… you're comparing the final result with some ground truth, has there been any cases where the ground truth it's like… Or actually… That might not be possible. But, like, has there been cases where, like, the ground truth is correct, but then there's some problems in the process?"}
{"speaker": "Participant", "text": "So yeah, for, like, initial, when writing the pipeline, we have that problem. So, it's in the validation agent, it's in our validation agent, where, the ground truth is correct, we are getting the correct response from the agent, but somehow our LLM, it's not working. So, our agent is not, specifying it valid. So, but it's not an LLM issue, it's not an agentic issue, it was a programmatical, like, initial debugging. It's not an error from LLM set, it's, like, a developer error, we have missed out something, or some line is not… some condition is not working as intended to be. It should be, like, output format error, because if we are getting, like, 1 in numeric, but it's 1.0, Both are same, but data types are different. It's one of the examples. So, we have fixed it, but it's, like, initial setup, and we are writing the code. It's before testing also."}
{"speaker": "Interviewer", "text": "Okay, I see."}
{"speaker": "Participant", "text": "And then… okay."}
{"speaker": "Interviewer", "text": "The next, question is more, like, open-ended, so if you can… design, like, an ideal, building multi-agent system workflow. So what kind of signals Or, like, information would, would be helpful."}
{"speaker": "Participant", "text": "Basically, first two should be the main agenda of the multi-agent workflow, input, output, and to determine exactly which agent LLM should be needed. And is it, like, needed, that's why we are using, or just to make it as a fancy LLM agentic term, that's what you are using… we are using. That, to difference, will be very much needed."}
{"speaker": "Interviewer", "text": "Okay. And input-output, okay."}
{"speaker": "Participant", "text": "Input-output is the base, we need that, and goal also of the project. It doesn't mean, like, we should have 10, 20 agents there in our project."}
{"speaker": "Interviewer", "text": "I see. Okay. And then… okay. And then, okay, I finally have some… also, like, more open-ended questions. And I think you also touched a little bit on it. So, like, for… like, just generally, what kind of problems do you think, multi-agent system is, like, especially appropriate and work the best?"}
{"speaker": "Participant", "text": "Oh, sorry, I couldn't get that part."}
{"speaker": "Interviewer", "text": "Okay, yeah, so, what kind of, tasks? Do you think a multi-agent system is, The most appropriate, or we should definitely choose multi-agent system for…"}
{"speaker": "Participant", "text": "where you should have at least one LLM call happening, and other is that the process of the pipeline should include more than one operation. That includes, like, end-to-end flow. What I mean by end-to-end flow is, like. If you are reading the data to output the data, so this is one operation, an extra one operation should be included. Rather than read and output, then we should use multi-agent flow."}
{"speaker": "Interviewer", "text": "Okay. And then… okay. I see. Yeah, so… I watched this, I think it was a video from, LaneGraph, but… I think their definition was kind of similar. Basically, whenever you need to make multiple tool calls, it's good to have multiple agents, because the more available tools for a single LLM, the less reliable it can be. Sometimes it doesn't know how to choose the right tool… tools."}
{"speaker": "Participant", "text": "Yeah, that's the right part. Yeah. Sometimes it doesn't know that. And also, one more thing, there is no harm to have, like, one operation, one tool. Sometimes people use multi-agent, but only on single agent, they involve multiple operations."}
{"speaker": "Interviewer", "text": "Yeah, yeah."}
{"speaker": "Participant", "text": "Yeah, we can have single tool, single operation."}
{"speaker": "Interviewer", "text": "Okay. Okay. And then, okay, and okay, I have a final question. We have 40 minutes. So, I think this is a little bit similar, but, just what are some… challenges that you can think of when you're, developing… it doesn't matter if it's, like, designing or actually implementing a multi-agent system. And, like, what do you think that can make this easier?"}
{"speaker": "Participant", "text": "When developing an agent, Yeah, rely on… so you're talking about as a developer point of view, right?"}
{"speaker": "Interviewer", "text": "Yeah, like a developer point of view."}
{"speaker": "Participant", "text": "Yeah, rely heavily on documentation."}
{"speaker": "Interviewer", "text": "on documentation?"}
{"speaker": "Participant", "text": "Yes, Langraph Langchain documentation. That's the best result you will get. Yeah, that's… Basically, because you're developing an agent workflow is not that hard when we talk about coding's point of view, but how you orchestrate it, that is the orchestration agent. That's the critical part. Because code is very simpl… similar."}
{"speaker": "Interviewer", "text": "Yeah. And by all…"}
{"speaker": "Participant", "text": "Easy to the…"}
{"speaker": "Interviewer", "text": "You mean, like,"}
{"speaker": "Participant", "text": "Connecting different agents together, import and output."}
{"speaker": "Interviewer", "text": "Infinite amount."}
{"speaker": "Participant", "text": "agent should receive what output, which agent should receive what input from which agent, and which produce what output, and that output should be input to which will… which and which all possible agents. That's the main part. So it's not a coding part."}
{"speaker": "Interviewer", "text": "But it's an operational orchestration part. Orchestration. And then I guess, like, system prompt as well, because you need to try…"}
{"speaker": "Participant", "text": "system problem. Yeah, that's for the LLM agent, because every agent won't be an LLM agent. Yeah. Okay. Cool."}
{"speaker": "Interviewer", "text": "Yeah, okay. And, that was all the questions I have, but, I think that was really helpful, because I think a lot of other people are just students, and you actually have some industry experience, so that's good. Yeah, and… I'm also surprised, because, like, people have, like, different, they use multi-agent systems for, like, completely different purposes. Some of them even used, like, a clinical… Something related to clinical. And there's also… One response that use, like, I think this is less… Similar to yours, but they use multiple agents to do debates. they, like, each agent debate against, like, other agents, to increase the overall accuracy of the response, I think."}
{"speaker": "Participant", "text": "Yeah, it will be, like, don't know. Might be a different use case, but sometime… It's not needed, also."}
{"speaker": "Interviewer", "text": "They're going to find some benchmark that's… that's going to prove their framework is better."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "Yeah, it's not always about branching out. If you implement same thing using a single agent or Python, single script."}
{"speaker": "Participant", "text": "You will… you will get that benchmark, but it doesn't mean that it's suitable for multi-law."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "But yeah, oh, that, that, that's…"}

