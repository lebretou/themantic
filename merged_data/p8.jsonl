{"speaker": "Interviewer", "text": "Okay, let's go ahead and start. So I'll start with a pretty abstract question. So. what is your definition of a multi-agent system? And, so, like, when you hear the term multi-agent system, what does it mean to you? How would you define?"}
{"speaker": "Participant", "text": "So, in my understanding, multi-agent system is a place where, it involves, like, different agents, but agents, it's not anymore a tool. It's some, like, LLM-based, like, service provider, which have certain capability and a definition. within the system. So, the definition should become in a way that it's compatible with other agents in the multi-system agents, and they can collaborate in a meaningful way."}
{"speaker": "Interviewer", "text": "I see. And, could you tell me about one or two representative projects that, you have worked on in the past, that used multi-agent system?"}
{"speaker": "Participant", "text": "Yeah, so I'll take one example in Amazon Rufus. I've done, like, multiple multi-agent systems. One example is, in Amazon Rufus, we built a multi-agent, system. To provide, like, product recommendations. Right. Product recommendations, it looks simple, but it comes with different pieces, where you need to, retrieve the information from a database. Making sure the products are legitimate, and then also, you need to find some deals. For example, when customers ask, can you give me, show me some products which, which is on sale? you should be able to find it. So, there are different components inside of it. Also, for sure, they come with, like, customer service pieces as well, because when customers say, oh, well, the product I bought this time is not great, can you help me, return this one, or can you help me update the, the… the mailing address. So, for that, you need to be able to, added. So, I can tell you in a high level, but I don't think I'm supposed to go into too much detail, because."}
{"speaker": "Interviewer", "text": "Yeah, yeah. Yeah."}
{"speaker": "Participant", "text": "Business, regulation, yeah. So, in the entire system, we have, like, 4 different agents, which is, like, initial design. And then one of the agents is… because, you know, in business, like, a lot of things you need to be very mindful of, especially legal-related. For example, when customers ask me, can you recommend some stock that I can investigate? It's definitely, outside of the scope or responsibility of a shopping Right. That's supposed to answer you, so you need to have a fallback agent, which is used to deal with those questions you are not… you are not supposed to answer. And that one has, like, a very, heavy business requirements and guardrail system. you need to process, so you definitely have one of them. And there are other three agents. I wouldn't go into too much detail, but they, like, collaborate together to get products, Also, There are contexts we'll be sharing with each other within the collaboration process. There are definitely some more advanced ways to deal with it. For example, you only choose to share specific context that is relevant to other agents' scope, but the thing is, like, something we're exploring right now, yeah."}
{"speaker": "Interviewer", "text": "Okay. So, what was your, main… responsibility in the project that you just described. Did you, work on, like. Did you work out the entire thing from scratch, or did you focus on a specific part, for example, like, writing system prompts, or… Working on, like, the higher level architecture."}
{"speaker": "Participant", "text": "I was everywhere, so at the beginning, it was, like, two, three scientists who started with it. One of them also come from memory, other than me."}
{"speaker": "Interviewer", "text": "Sure."}
{"speaker": "Participant", "text": "So we get started at the beginning, we build a demo, and after the demo, like, in business, the way it works is you build a demo and prove it works, and if leaders think it's, like, a place where it's worth investigating, and then more people will flood in and help you to shipping to production. So, at the beginning, it was, like, 3 of us to design everything. It's more sort of like a local Python, proof of concept. But later on, when it gets funded, it will, like, our product managers coming to help designing, and our UX, designers also coming to help improve the customer experience. And then, like, engineers, like, coming to, like, for example. One of the biggest problems we are facing… we were facing, is the latency. Because it injects a lot of product information. Where… Also, the prompt is, like, super big, so you need to do a lot of, like, prompt optimizations, where what they did is, like, prompt caching and also, context summarization. So it's a lot of, like, engineering, challenges as well. So, like, it's a collaboration."}
{"speaker": "Interviewer", "text": "Okay, and so currently you have just, showed the prototype, you haven't really gone into the production."}
{"speaker": "Participant", "text": "Oh, it's already in production, 100%."}
{"speaker": "Interviewer", "text": "It's in production, okay. And then, did you use any framework, like LaneChain, LaneGraph, or some Amazon."}
{"speaker": "Participant", "text": "We use Amazon's internal thing called, Agent Core."}
{"speaker": "Interviewer", "text": "Agent Core. Yeah, Agent Core, yeah, because it's."}
{"speaker": "Participant", "text": "It's Amazon's own service, so it's, like, makes more sense to use it directly out than other MCP service."}
{"speaker": "Interviewer", "text": "Okay, and could you talk more about the prompt, optimization process? Well… Was it a lot of, like, trial and error, or was it, there's, like, a systematic way of doing that?"}
{"speaker": "Participant", "text": "So, prompt optimization, in a sense, I think it's, like, a very broad way. I think the biggest technique they use is prompt caching. It's, like, a pure engineering problem, where, like, the… the agent… when the agent, like, LLM is being called, like, the prompting can be, like, cached, so they avoid, like, Over calling. But actually, it wasn't, like, the prompt optimization. It was, So, I actually did both. So, prompt optimization we did, and also we did the, context optimization. It depends on what is your question, like, which part do you…"}
{"speaker": "Interviewer", "text": "You said that you had, like, a super long prompt,"}
{"speaker": "Participant", "text": "Yeah, yeah."}
{"speaker": "Interviewer", "text": "in the end. So I was wondering about, like, how… what steps did you take to eventually get like, came to that super long prompt. Was it, like, super long in the very beginning, or did you…"}
{"speaker": "Participant", "text": "Yeah, it's like an incremental thing, like, when, in business, you need to incrementally add, like, different customer experience. For example, product comparison, like, product recommendation, a lot of experience you need to add on top of it. So, it's like an incremental process. At the beginning, it can be, like, a very short. Later on, when, like, more and more collaborators come in, they are saying, oh, can you also support our service or feature? So that's the process, how, like, the prompt is getting longer and longer. And also, it definitely comes with a lot of, like, conflicts that you need to pay attention and solve."}
{"speaker": "Interviewer", "text": "Okay. Do you mind if I ask, like, the… well… so, eventually, what is, like, the overall structure of the prompt? Are there some… Things that you define, for example, like… What kind of input will the agent get? What kind of output should the agent… or how should it communicate with other agents? And some context, for sure."}
{"speaker": "Participant", "text": "I don't think I can get into super detail, but the way I can say is it depends on the prompt, the multi-system designing at the very beginning, so that you need to, for example, one agent ingests another agent's output."}
{"speaker": "Interviewer", "text": "Right. So, need to making sure that… tell this agent, so, like, agent, you have… need to have a router, right? Orchestrator. So, orchestrator, you need to understand, like, which is the… what is the workflow. So, and also what is the input and output from each agent."}
{"speaker": "Participant", "text": "And then within the sub-agent, you need… also need to tell the sub-agent, hey, you need to make sure your output format can be ingested by, Another agent which is taking your output as input. Yeah."}
{"speaker": "Interviewer", "text": "That's it. So… For… for this project, did you initially… So, like, given the goal. Given the task that you want to solve, or the problem that you want to solve, did you initially think that, multi-agent system is the best solution, or did you, like, try with just a single agent, single LLM?"}
{"speaker": "Participant", "text": "Yeah, this is a very good question. So, at the very beginning, Because we were, like, we were a bunch of folks who just got started to work within, like, one or two years. We are not, like, super senior, so we didn't know that, there are, like, so many collaborations in the future, so at the very beginning, we actually started with, like, single agent."}
{"speaker": "Interviewer", "text": "But the thing is, like, when the…"}
{"speaker": "Participant", "text": "Problem is getting larger and larger, and your prompt can be easily over 1,000 lines."}
{"speaker": "Interviewer", "text": "At that point."}
{"speaker": "Participant", "text": "You start to realize it's not gonna last. It's not my last because, like, it's, like, cost very heavy. The latency is, like, a super, Sorry, one second, so Friday, November 20th… Yeah, so, so, so the latency was, like, super long, and also, it started to hallucinate, because it's injected."}
{"speaker": "Interviewer", "text": "Sorry to that."}
{"speaker": "Participant", "text": "too many… too many information, too much information, and they're following too many guidelines. So, this is the point. It becomes like a design problem. Design problem that you start to understand. Because at Amazon, like, it's a business company, there are a lot of policies you need to follow."}
{"speaker": "Interviewer", "text": "And also, there are a lot of components, APIs, database."}
{"speaker": "Participant", "text": "tools you can use. So, it, it, it increased the difficulty of the multi-agent. So, in this, as time goes by, I like the multi-agent is a very natural way, because, it helps with the scaling, scaling up. And, increase the speed of, like, onboarding different customer experience. I see. Okay."}
{"speaker": "Interviewer", "text": "And then, so you said that you… at first, you tried a single LLM, and then it, naturally became a multi-agent system."}
{"speaker": "Participant", "text": "boom."}
{"speaker": "Interviewer", "text": "For the high-level structure, like, what agents are there going to be? What is, like, the role of each agent? Did the high-level structure of your system also change over time?"}
{"speaker": "Participant", "text": "It changes. So, yeah, there are a lot of, like, non-technical discussions. Because in company, everybody wants to make sure their product is successful, so, the service provider or, like, customer experience provider from other teams, they want to put their service into Rufus. So that they can benefit from the ruthless traffic. So, people are fighting to send things in and out. So every time, like, this sort of… I… this is some, like, non-technical discussions, like, independent contributor doesn't care."}
{"speaker": "Interviewer", "text": "Excellent."}
{"speaker": "Participant", "text": "But every time there's, like, updates, we need to update the system. It's, it's, it's a… it's a challenging thing, but we built something… so there is one paper in last year's iClear, ICML. I say MLI Clears, I forgot. It's like the oral paper. Oral paper, in a sense, it's like the best paper, sort of thing. So, it's called AFLO. I can share you the paper link later on. It's like a… A floor. It's like workflow generation. Automatic workflow generation, where you can have, like, reward modeling. For example, when you delete or increase some feature of the… one of the sub-agents, and then use, build some pipeline, get inspired from the Aflow, and use… use it to let The AFLO itself to automatically update each prompt scope. Each prompts our responsibility, so that the updated multi-agent system can still function and they're compatible with each other. Yeah, so this is, like, some research idea we tried. It somehow worked, but I… there's no guarantee that it's the best way to automation the entire process, because…"}
{"speaker": "Interviewer", "text": "So… Okay. So I've… I'm understanding this correctly, it's… Generating prompt, generating even agents on the fly."}
{"speaker": "Participant", "text": "It's a modification, it's not generating."}
{"speaker": "Interviewer", "text": "Oh, it's a modif, okay. Yeah. It's modifying the current…"}
{"speaker": "Participant", "text": "existing agents' scope? Because if you think about agents, essentially it's like a prompt. prompt, connect those different tools, APIs, if necessary."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "So, again, I guess the things that you experimented the most, For that project was the context management and then the system prompts."}
{"speaker": "Participant", "text": "So, it was the tool calling. Especially, we started this project with some, like, I won't be able to tell you the model, but it's, like, very early version of some model."}
{"speaker": "Interviewer", "text": "Oh."}
{"speaker": "Participant", "text": "We're trying a different type of the model from different companies. At the very beginning, like, the very… it's very challenging to have the two calling to… To be accurate. So it became a challenge. But later on, when the model is, like, getting better and better, because, like, so many models got released this year."}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "this problem, like, better. So, tool calling and the, like, the rack system, Rich, are you familiar with RAC?"}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "Yeah, yeah, so, the tool calling the rack was the very first challenge we… we have. But, like, the summarization, optimization, it's the problem that we'll later on have, yeah."}
{"speaker": "Interviewer", "text": "Okay. So… Could you also tell me, how did you, like, how did you monitor your system, when, let's say you have a prototype, and then you want to make sure that it's working correctly, each agent is doing, like, the job that they should be doing, and then the output is also correct?"}
{"speaker": "Participant", "text": "Yeah, so basically there's no way to do this monitoring, because it's interactive, like, people interact with it, and everything was on the fly. So there's no way to… Be aware, oh, how my system is good or not. But, you can still do sanity check, right? Before launching, you need to have some, like, offline evaluation to making sure what you're getting is correct, before you're sending to production. And this offline evaluation is some, like, data, like, different, like, employees. to work on, it's, like, making sure it's, like, as close as the, like, actual, customer input. The… so we're using this, like, the numbers generated by this offline dataset as, like, a proxy for how good it is."}
{"speaker": "Interviewer", "text": "Okay. So… I guess, yeah, that's just, like, more evaluation, making sure the system is behaving the way that it should."}
{"speaker": "Participant", "text": "Evaluation is a very important problem, but it's quite challenging, yeah."}
{"speaker": "Interviewer", "text": "Okay. Yeah, so I was actually asking more about, like, when you were developing, Was there any, so, like, how did you check, let's say, the intermediate output of each agent?"}
{"speaker": "Participant", "text": "This is more sort of an engineering problem. Like, the output of each agent will be put into some service, and this service will be connected to the next one. sometimes the error happens, but the thing is, like, now, like, the models is, like, trying to be better, following the output, syntax, for example, JSON or MD. Yeah. Like, different type of the format. So, it's really hard to define it's correct or incorrect, as long as the output, like, the format aligns with whatever the next agent is."}
{"speaker": "Interviewer", "text": "What else?"}
{"speaker": "Participant", "text": "It will work. It's just a matter of, like, how good it works or how bad it works. So, there is basically no arrows you can detect. If it's there, even if there's error, it will be sent to retry it the next time, and the next turn… the next time, the error problem wouldn't be there."}
{"speaker": "Interviewer", "text": "Okay. So what was, like, the most common error or, like, bug that you ran into? I think you mentioned, tool calling. And hallucinating at the beginning."}
{"speaker": "Participant", "text": "So I would still say it's a hallucination, yeah."}
{"speaker": "Interviewer", "text": "Hallucination."}
{"speaker": "Participant", "text": "Yeah, it's still the hallucination. It's… it's not even a bug. It wouldn't show you any bug."}
{"speaker": "Interviewer", "text": "It's not a bug."}
{"speaker": "Participant", "text": "It's just you realize what it says, like, sometimes it's… it's changing, especially under pressure. For example, if you ask for some question that it does not know, you will say, oh, I don't know at the beginning, which is normal. But if you keep sending pressure, you must know you are, you're in, you are, like, whatever chatbot that you are so super, you must tell me this and that. When, like, customers repeat this sort of, like, high-pressure queries, it starts to hallucinate."}
{"speaker": "Interviewer", "text": "So do you think that this hallucination problem… I mean, it can definitely be reduced by having a stronger model, but it doesn't come out every day. So just from an engineering perspective, how… like, what are some… Actions that you can take to try to, like, minimize hallucination As much as possible."}
{"speaker": "Participant", "text": "Yeah, like, it really depends on how would you view this problem as a… So, this problem… I think it can be solved or improved, I would say. I don't think it can be solved. It can be improved. two ways that, like, for example, if you have, like, a small model or, like, open source model, you can fine-tune it, like, so that, like, DPO, GIPO, to making sure, it has, like, stronger regulation for the, actuality. It will help, it will help. I tried. It helps, but it wouldn't help you to solve the problem 100%. Second thing is, you can have some basic guardrails. For example, prevent model… so, it's like guardrail, it's more sort of like prevent model from saying some legal legal requirements, right? But for the hallucination, I think there is some sort of question Gadriel can help you to… to do, but, like, Galleria wouldn't be able to solve 100% of the problem. This is, like, very… very much the biggest pain point, because if you think about, multi-agent system, it's actually a cascaded process. Even though your model have, like, 99% of accuracy. It looks great, but if you cascade the error rate at the end, it's, like, it's like 99 to the exponential of, like, 5 or 6. It won't fail, yeah."}
{"speaker": "Interviewer", "text": "Yeah. Right, okay. And then… so you also said that, The… at industry, you first have, like, a working prototype, you present it to your manager. I wanted to ask, so, like. at what point did you think that, okay, this prototype is pretty ready, this pipeline is pretty reliable, pretty consistent, I think… it's okay now for me to share with my manager. Or even for production, like, what… like, how do you eventually decide that, okay, this, this pipeline or this multi-agent system can… be actually."}
{"speaker": "Participant", "text": "Actually, this is not determined by me. So, like, prototype, it's, rather, like, I have more control over it, because prototype, I can… I think as long as the functions I envision, like the 3 or 4 most important customer experience, I, if I'm able to, deliver that, I was confident to talk to my manager and my director, which is fine."}
{"speaker": "Interviewer", "text": "Okay."}
{"speaker": "Participant", "text": "But even, like, launching to production, it's some decision that, like, the director or VP, they need to make, so that's, sort of out of my control."}
{"speaker": "Interviewer", "text": "I see. I see. Okay. And, okay, I have another question, which is, also just for developing. the multi-agent system, do you think there's any… Features, or, like, interface? That could speed up that process. Or what are some, like, features that's nice to have?"}
{"speaker": "Participant", "text": "Yeah, this is a very good question. If you look back into the interactive machine learning domain, which is the problem space, I briefly touched it a little bit back in my PhD. So, later on, there is, like, I believe. There… in deep learning, you need to have, like, different layers, like, fully cleansed layer, dense layer, whatever, polling layer. And there have been some people who did, like, interactive, machine learning, where they… you have, like, a UI, different layers come with, like, LEGO blocks. You can drag them into the space, and then using a line to connect it, like, specify what is the input and output size, like, for example, 16, polling layer will be connected to, like, 64, like, densely, whatever. So that's the, like, interactive way to do it. And then, machine will use translation to translate this sort of idea into implementations and help you to do the implement. So, like, building a machine learning, deep learning model became, like, an interactive way. By the way, did you record a meeting?"}
{"speaker": "Interviewer", "text": "Yeah, yeah."}
{"speaker": "Participant", "text": "Okay, okay, sounds good. Yeah, so… That's actually a good idea for multi-agent, because multi-agent, basically, it comes with three things. First thing, like, multi-agent design. Structure design, right? And then, in… other than structure design, within Orchestrator, you need to let Orchestrator know what are the other sub-agents with the definition. That's the first thing. Second thing, for the sub-agent, you need to specify this agent and that agent, what kind of external database you are… be able to access, because REG is, like, a very important thing."}
{"speaker": "Interviewer", "text": "Right now, because Model, there are a lot of domain knowledge that Model was not able to access."}
{"speaker": "Participant", "text": "For example, if you're in UMD, let's say you want to access your, like, UMD internal database for, like, student and employee information. That's something that the LLM doesn't know, because it's not pre-trained on that. So, you need to… the second LEGO block is you need to let each sub-agent know what kind of tools it can access to, and give the tool definition, give the tools… sorry, what kind of APIs, by API, you can actually call it a tool, because essentially it's tool calling, right? So, for each tool, so what is each tool's definition? What is the exemplary input and output."}
{"speaker": "Interviewer", "text": "For each one. This thing you need to have."}
{"speaker": "Participant", "text": "And third thing, if you put everything into integrity, you need to be making sure that, like, the MCP and the connections between sub-agent and communication between sub-agents to the orchestrator Yeah, this is something that I envision we can use, like, some sort of interactive UI to build this sort of system. I don't think there's, like, too challenging things. But it really depends on… The complexity you and their Good, right? Yeah. But it definitely, improved from research perspective. It improves the accessibility, it improves the… like, the generalizability and the, like, making sure that people who are not that technical can also be accessed to model aging. I don't see… so, I was thinking about this research idea a while back, and I did some, like, literature where nobody was doing it."}
{"speaker": "Interviewer", "text": "But it's, like, a very engineering-heavy project."}
{"speaker": "Participant", "text": "new myself working Amazon doesn't allow me to have a lot of bandwidth to work on it, yeah."}
{"speaker": "Interviewer", "text": "I think there's actually, some interfaces like that."}
{"speaker": "Participant", "text": "Oops."}
{"speaker": "Interviewer", "text": "I… I can share a screen real quick. I know people have been trying it, there's also a couple tools available out there, but I think the problem With those tools is that they don't… hmm… So this is one of the tools. They have…"}
{"speaker": "Participant", "text": "It's already there. Way."}
{"speaker": "Interviewer", "text": "Started there, yeah, yeah, they have, like, agents… You can also define, like, the tools… Also, RAC Database, I think."}
{"speaker": "Participant", "text": "I see, yes. I see, okay. Yeah."}
{"speaker": "Interviewer", "text": "But it's, I don't know, from what I have been… from my experience, or not my experience, but, like, from the interviews I have done so far, I feel like not many people are using it. I'm not sure, the reason why."}
{"speaker": "Participant", "text": "So, yeah, I can tell you the reason. So… I'll use one example, prompt tuning. Very easy and straightforward thing, right?"}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "very beginning, like, the, like, engineers and, like, the PMs in Amazon, they're not there to tune a prompt. They think it's, like, a very technical thing. So they send it to scientists, but scientists don't want to tune a prompt. It's like, there's no sense for a code there. So there is, like, a misunderstanding, or, like, the learning curve, where people start to think, oh, aging, like, super complicated, like, a lot of things need to be done. Anything… mistake made can be easily propagated. So, I'm viewing this as, like, one of the reasons for why not a lot of people are using it, because, first of all, like, people who work on agents, engineers and scientists, they don't need this tool. They know how to make…"}
{"speaker": "Interviewer", "text": "You can just use LendChain."}
{"speaker": "Participant", "text": "Yeah, nothing is needed by PMs. PMs and designers, UX designers. But those people still intimidated by this, like, oh, this, like, complicated thing is, like, very technical, I cannot use it."}
{"speaker": "Interviewer", "text": "And, yeah. And if you're just designing or, like, envisioning, then you don't need something that actually works. You can just use a PowerPoint, right? Yeah, I also had the same thought. I think it's just kind of awkward. I feel like it's not easy enough for people who don't have any experience to build."}
{"speaker": "Participant", "text": "A working pipeline."}
{"speaker": "Interviewer", "text": "But it's also, like, Kind of a toy to actual engineers."}
{"speaker": "Participant", "text": "yeah, I agree, I agree."}
{"speaker": "Interviewer", "text": "Okay. And then… So… We're… Trying to locate the question. Okay, and then… I'm gonna go back to being a little bit more general. So, for what type of problems you think a multi-agent system worked the best? I think you already talked about About it, a little bit."}
{"speaker": "Participant", "text": "I see. So, hmm… I… to be honest, I still don't believe multi-agent system can be that reliable for very complicated problems. for example, like, a lot of, like, agents need to back and forth send information, it's an iteration, so this thing, I don't think it's the best use case. I believe it's the use case where So, abstract… my idea here. I believe it's, like, quite complicated work. That, can be done by single agent, but when be done by a single agent, you need to take some trade-off, either hallucination, either latency, or either usability. So that… I think multi-aging system is a way to scale up But it's functionality-wise, I still think, like, the multi-agent system It's just as good as a single agent system, if you want it to do something. It's not like a superhero or superpower who, like, could, like, be advanced on a lot of, like, performance-wise. It's just, like, a way to scale up, and to split the workload so that model will less hallucinate."}
{"speaker": "Interviewer", "text": "I see. Okay, that was actually the last question from what I've prepared, but before we end, I actually have a very specific question. So for the system prompts. when you're developing, are they, did you… like, where do you… how, like, how did you edit it? Did you keep it just in the, like, code editor as a long… super long string, or did you have it somewhere else?"}
{"speaker": "Participant", "text": "Oh, no, it's like the Python console, like VS Code, Python, Python file. It's like prompt equals to comma, Like, we're betting a coma, it's, like, a lot of prompts, like…"}
{"speaker": "Interviewer", "text": "So, it's just a super long string in Python. Okay. Okay. So, the reason why I ask that is because, I have interviewed, probably, like, 7, 8 people now, and then, one of the problems The most common problem is probably… writing system prompts. And then… So… my mentor and I are thinking about doing something about it, and so, I actually interviewed another person, she interned at Amazon, and then she… she had this 3-month internship. to build, like, some sort of multi-agent system, but she spent almost 2 months just writing system prompts. So… It was… it was very… tedious, because, she was just, like, traveling and erring. She would have, like, a prompt, and then she would run the system, just wait for, like, unexpected behavior to occur, and then manually include that unexpected behavior into the problem. Be like, oh, do not do this, do not do that. But then, they eventually turned into this framework I don't know if you have heard…"}
{"speaker": "Participant", "text": "Auto prompt."}
{"speaker": "Interviewer", "text": "It's… it uses… It's a framework, and it uses some prompt optimization technique. So basically, instead of writing system prompt yourself, you just define the input and output, and you provide some in-context learning examples, and then, it tries to determine the best route for that set of input and output."}
{"speaker": "Participant", "text": "Yeah, I think, for example, Claude itself has, like, the prompt optimization."}
{"speaker": "Interviewer", "text": "Yeah."}
{"speaker": "Participant", "text": "Yeah."}
{"speaker": "Interviewer", "text": "So we're currently brainstorming, but we feel like We wanted to do something, maybe like a visual… something visual about, editing your prompt, because, at least I think that, so system prompts for multi-agent system, they usually follow some structure. They always have some, inputs and outputs and, like you said, like, tools, tools definitions, also the context. So we're thinking… maybe, maybe do something about that. For example, like, visualize the structure. Inputs and outputs. Things like that."}
{"speaker": "Participant", "text": "Yeah, so I, I think… I imagine there something can be done over here, it's like an interpretation tool, in the sense that, for example, it's not building a multi-agent system, it's, it's more so understanding multi-agent system, and the debugging and a problem, problem shooting. For example, if I gave you, like, super long multi-system pro… multi-agent system. Can you give me a tool so that this tool can help me, visualize in a diagram that… how does… what is the workflow of this multi-agent system? And what is the input-output of this multi-agent system? And then tell me, what is the gap? Gap, meaning there is some functionality that orchestrator thinks the sub-agent can be done, but the sub-agent itself, or, like, the collaboration itself, has some gap. So, this tool can be… help to diagnose the problem, and help for the future refinement. It's also, like, a tool that helps with, like, interpretation and the, like, transparency, improve the, like, the multi-aging transparency. It will be useful, yeah."}
{"speaker": "Interviewer", "text": "so, I'm not sure… If this is… But I think, AWS…"}
{"speaker": "Participant", "text": "Already has it."}
{"speaker": "Interviewer", "text": "Already has it, it's called… AWS Observability."}
{"speaker": "Participant", "text": "observability. Observability multi-agent."}
{"speaker": "Interviewer", "text": "Aging…"}
{"speaker": "Participant", "text": "Really?"}
{"speaker": "Interviewer", "text": "I'm not sure if it's…"}
{"speaker": "Participant", "text": "Skywalk Aging Corps of the Office of Observability. It's called AWS, Bedrock Aging Core Observability."}
{"speaker": "Interviewer", "text": "Yeah, yeah. Provides detailed visualization of the aging workflow."}
{"speaker": "Participant", "text": "Yeah, yeah, it's already provided. Yeah."}
{"speaker": "Interviewer", "text": "The reason why I know this is I took, AWS AI Practitioner, certificate."}
{"speaker": "Participant", "text": "Okay, yeah. Yeah, the aging world is, like, developing too fast, yeah."}
{"speaker": "Interviewer", "text": "Yeah, yeah. But okay, we can end, it's… I think it's about time. But yeah, just… I'll stop recording."}
