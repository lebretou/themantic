WEBVTT

1
00:00:01.930 --> 00:00:12.109
Zhongzheng Xu: Okay, let's go ahead and start. So I'll start with a pretty abstract question. So.

2
00:00:12.140 --> 00:00:22.049
Zhongzheng Xu: what is your definition of a multi-agent system? And, so, like, when you hear the term multi-agent system, what does it mean to you? How would you define?

3
00:00:22.260 --> 00:00:42.140
Ziwei Dong: So, in my understanding, multi-agent system is a place where, it involves, like, different agents, but agents, it's not anymore a tool. It's some, like, LLM-based, like, service provider, which have certain capability and a definition.

4
00:00:42.170 --> 00:00:53.450
Ziwei Dong: within the system. So, the definition should become in a way that it's compatible with other agents in the multi-system agents, and they can collaborate in a meaningful way.

5
00:00:55.250 --> 00:01:04.889
Zhongzheng Xu: I see. And, could you tell me about one or two representative projects that, you have worked on in the past, that used multi-agent system?

6
00:01:04.890 --> 00:01:19.580
Ziwei Dong: Yeah, so I'll take one example in Amazon Rufus. I've done, like, multiple multi-agent systems. One example is, in Amazon Rufus, we built a multi-agent, system.

7
00:01:19.770 --> 00:01:24.880
Ziwei Dong: To provide, like, product recommendations.

8
00:01:24.890 --> 00:01:33.410
Ziwei Dong: Right. Product recommendations, it looks simple, but it comes with different pieces, where you need to, retrieve the information from a database.

9
00:01:33.410 --> 00:01:45.550
Ziwei Dong: Making sure the products are legitimate, and then also, you need to find some deals. For example, when customers ask, can you give me, show me some products which, which is on sale?

10
00:01:45.550 --> 00:02:03.309
Ziwei Dong: you should be able to find it. So, there are different components inside of it. Also, for sure, they come with, like, customer service pieces as well, because when customers say, oh, well, the product I bought this time is not great, can you help me, return this one, or can you help me update the,

11
00:02:03.340 --> 00:02:07.779
Ziwei Dong: the… the mailing address. So, for that, you need to be able to,

12
00:02:08.120 --> 00:02:15.850
Ziwei Dong: added. So, I can tell you in a high level, but I don't think I'm supposed to go into too much detail, because.

13
00:02:15.850 --> 00:02:17.330
Zhongzheng Xu: Yeah, yeah. Yeah.

14
00:02:17.330 --> 00:02:25.169
Ziwei Dong: Business, regulation, yeah. So, in the entire system, we have, like, 4 different agents, which is, like, initial design.

15
00:02:25.210 --> 00:02:39.669
Ziwei Dong: And then one of the agents is… because, you know, in business, like, a lot of things you need to be very mindful of, especially legal-related. For example, when customers ask me, can you recommend some stock that I can investigate?

16
00:02:39.670 --> 00:02:45.319
Ziwei Dong: It's definitely, outside of the scope or responsibility of a shopping

17
00:02:45.370 --> 00:03:00.859
Ziwei Dong: Right. That's supposed to answer you, so you need to have a fallback agent, which is used to deal with those questions you are not… you are not supposed to answer. And that one has, like, a very, heavy business requirements and guardrail system.

18
00:03:00.860 --> 00:03:11.760
Ziwei Dong: you need to process, so you definitely have one of them. And there are other three agents. I wouldn't go into too much detail, but they, like, collaborate together to get products,

19
00:03:11.790 --> 00:03:18.460
Ziwei Dong: Also, There are contexts we'll be sharing with each other within the collaboration process.

20
00:03:19.000 --> 00:03:33.979
Ziwei Dong: There are definitely some more advanced ways to deal with it. For example, you only choose to share specific context that is relevant to other agents' scope, but the thing is, like, something we're exploring right now, yeah.

21
00:03:34.150 --> 00:03:37.479
Zhongzheng Xu: Okay. So, what was your, main…

22
00:03:37.620 --> 00:03:44.060
Zhongzheng Xu: responsibility in the project that you just described. Did you, work on, like.

23
00:03:44.260 --> 00:03:51.599
Zhongzheng Xu: Did you work out the entire thing from scratch, or did you focus on a specific part, for example, like, writing system prompts, or…

24
00:03:51.750 --> 00:03:55.569
Zhongzheng Xu: Working on, like, the higher level architecture.

25
00:03:55.710 --> 00:04:05.479
Ziwei Dong: I was everywhere, so at the beginning, it was, like, two, three scientists who started with it. One of them also come from memory, other than me.

26
00:04:05.950 --> 00:04:06.540
Zhongzheng Xu: Sure.

27
00:04:06.540 --> 00:04:24.879
Ziwei Dong: So we get started at the beginning, we build a demo, and after the demo, like, in business, the way it works is you build a demo and prove it works, and if leaders think it's, like, a place where it's worth investigating, and then more people will flood in and help you to shipping to production.

28
00:04:24.990 --> 00:04:35.859
Ziwei Dong: So, at the beginning, it was, like, 3 of us to design everything. It's more sort of like a local Python, proof of concept.

29
00:04:36.010 --> 00:04:53.269
Ziwei Dong: But later on, when it gets funded, it will, like, our product managers coming to help designing, and our UX, designers also coming to help improve the customer experience. And then, like, engineers, like, coming to, like, for example.

30
00:04:53.270 --> 00:04:57.500
Ziwei Dong: One of the biggest problems we are facing… we were facing, is the latency.

31
00:04:57.510 --> 00:05:01.180
Ziwei Dong: Because it injects a lot of product information.

32
00:05:01.270 --> 00:05:02.320
Ziwei Dong: Where…

33
00:05:02.620 --> 00:05:17.280
Ziwei Dong: Also, the prompt is, like, super big, so you need to do a lot of, like, prompt optimizations, where what they did is, like, prompt caching and also, context summarization. So it's a lot of, like, engineering,

34
00:05:17.480 --> 00:05:20.490
Ziwei Dong: challenges as well. So, like, it's a collaboration.

35
00:05:21.050 --> 00:05:30.660
Zhongzheng Xu: Okay, and so currently you have just, showed the prototype, you haven't really gone into the production.

36
00:05:30.660 --> 00:05:32.550
Ziwei Dong: Oh, it's already in production, 100%.

37
00:05:32.550 --> 00:05:34.180
Zhongzheng Xu: It's in production, okay.

38
00:05:34.340 --> 00:05:42.500
Zhongzheng Xu: And then, did you use any framework, like LaneChain, LaneGraph, or some Amazon.

39
00:05:42.500 --> 00:05:46.519
Ziwei Dong: We use Amazon's internal thing called, Agent Core.

40
00:05:46.520 --> 00:05:50.349
Zhongzheng Xu: Agent Core. Yeah, Agent Core, yeah, because it's.

41
00:05:50.440 --> 00:05:56.180
Ziwei Dong: It's Amazon's own service, so it's, like, makes more sense to use it directly out than other MCP service.

42
00:05:56.350 --> 00:06:04.620
Zhongzheng Xu: Okay, and could you talk more about the prompt, optimization process? Well…

43
00:06:04.850 --> 00:06:12.069
Zhongzheng Xu: Was it a lot of, like, trial and error, or was it, there's, like, a systematic way of doing that?

44
00:06:12.070 --> 00:06:23.109
Ziwei Dong: So, prompt optimization, in a sense, I think it's, like, a very broad way. I think the biggest technique they use is prompt caching. It's, like, a pure engineering problem, where, like, the…

45
00:06:23.420 --> 00:06:30.609
Ziwei Dong: the agent… when the agent, like, LLM is being called, like, the prompting can be, like, cached, so they avoid, like,

46
00:06:30.800 --> 00:06:37.200
Ziwei Dong: Over calling. But actually, it wasn't, like, the prompt optimization. It was,

47
00:06:37.780 --> 00:06:49.000
Ziwei Dong: So, I actually did both. So, prompt optimization we did, and also we did the, context optimization. It depends on what is your question, like, which part do you…

48
00:06:49.170 --> 00:06:53.169
Zhongzheng Xu: You said that you had, like, a super long prompt,

49
00:06:53.170 --> 00:06:53.850
Ziwei Dong: Yeah, yeah.

50
00:06:53.850 --> 00:07:02.469
Zhongzheng Xu: in the end. So I was wondering about, like, how… what steps did you take to eventually get

51
00:07:02.670 --> 00:07:09.580
Zhongzheng Xu: like, came to that super long prompt. Was it, like, super long in the very beginning, or did you…

52
00:07:09.580 --> 00:07:16.709
Ziwei Dong: Yeah, it's like an incremental thing, like, when, in business, you need to incrementally add, like, different customer experience.

53
00:07:18.200 --> 00:07:26.840
Ziwei Dong: For example, product comparison, like, product recommendation, a lot of experience you need to add on top of it.

54
00:07:27.000 --> 00:07:31.670
Ziwei Dong: So, it's like an incremental process. At the beginning, it can be, like, a very short.

55
00:07:32.200 --> 00:07:39.820
Ziwei Dong: Later on, when, like, more and more collaborators come in, they are saying, oh, can you also support our service or feature?

56
00:07:40.150 --> 00:07:48.869
Ziwei Dong: So that's the process, how, like, the prompt is getting longer and longer. And also, it definitely comes with a lot of, like, conflicts that you need to pay attention and solve.

57
00:07:49.340 --> 00:07:53.210
Zhongzheng Xu: Okay. Do you mind if I ask, like,

58
00:07:53.550 --> 00:08:01.560
Zhongzheng Xu: the… well… so, eventually, what is, like, the overall structure of the prompt? Are there some…

59
00:08:01.730 --> 00:08:04.150
Zhongzheng Xu: Things that you define, for example, like…

60
00:08:04.490 --> 00:08:15.369
Zhongzheng Xu: What kind of input will the agent get? What kind of output should the agent… or how should it communicate with other agents? And some context, for sure.

61
00:08:16.260 --> 00:08:32.199
Ziwei Dong: I don't think I can get into super detail, but the way I can say is it depends on the prompt, the multi-system designing at the very beginning, so that you need to, for example, one agent ingests another agent's output.

62
00:08:32.230 --> 00:08:46.159
Zhongzheng Xu: Right. So, need to making sure that… tell this agent, so, like, agent, you have… need to have a router, right? Orchestrator. So, orchestrator, you need to understand, like, which is the… what is the workflow. So, and also what is the input and output from each agent.

63
00:08:46.230 --> 00:08:55.259
Ziwei Dong: And then within the sub-agent, you need… also need to tell the sub-agent, hey, you need to make sure your output format can be ingested by,

64
00:08:55.650 --> 00:08:59.500
Ziwei Dong: Another agent which is taking your output as input.

65
00:08:59.600 --> 00:09:00.310
Ziwei Dong: Yeah.

66
00:09:00.840 --> 00:09:13.319
Zhongzheng Xu: That's it. So… For… for this project, did you initially… So, like, given the goal.

67
00:09:13.440 --> 00:09:27.169
Zhongzheng Xu: Given the task that you want to solve, or the problem that you want to solve, did you initially think that, multi-agent system is the best solution, or did you, like, try with just a single agent, single LLM?

68
00:09:27.330 --> 00:09:31.190
Ziwei Dong: Yeah, this is a very good question. So, at the very beginning,

69
00:09:31.350 --> 00:09:47.340
Ziwei Dong: Because we were, like, we were a bunch of folks who just got started to work within, like, one or two years. We are not, like, super senior, so we didn't know that, there are, like, so many collaborations in the future, so at the very beginning, we actually started with, like, single agent.

70
00:09:47.370 --> 00:09:49.349
Zhongzheng Xu: But the thing is, like, when the…

71
00:09:49.350 --> 00:09:54.569
Ziwei Dong: Problem is getting larger and larger, and your prompt can be easily over 1,000 lines.

72
00:09:54.570 --> 00:09:55.690
Zhongzheng Xu: At that point.

73
00:09:55.690 --> 00:09:58.089
Ziwei Dong: You start to realize it's not gonna last.

74
00:09:58.390 --> 00:10:04.389
Ziwei Dong: It's not my last because, like, it's, like, cost very heavy. The latency is, like, a super,

75
00:10:04.940 --> 00:10:08.129
Ziwei Dong: Sorry, one second, so Friday, November 20th…

76
00:10:09.060 --> 00:10:16.640
Ziwei Dong: Yeah, so, so, so the latency was, like, super long, and also, it started to hallucinate, because it's injected.

77
00:10:16.640 --> 00:10:17.030
Zhongzheng Xu: Sorry to that.

78
00:10:17.030 --> 00:10:28.509
Ziwei Dong: too many… too many information, too much information, and they're following too many guidelines. So, this is the point. It becomes like a design problem. Design problem that you start to understand.

79
00:10:28.660 --> 00:10:33.620
Ziwei Dong: Because at Amazon, like, it's a business company, there are a lot of policies you need to follow.

80
00:10:33.760 --> 00:10:37.870
Zhongzheng Xu: And also, there are a lot of components, APIs, database.

81
00:10:37.900 --> 00:10:52.399
Ziwei Dong: tools you can use. So, it, it, it increased the difficulty of the multi-agent. So, in this, as time goes by, I like the multi-agent is a very natural way, because, it helps with the scaling, scaling up.

82
00:10:52.540 --> 00:10:57.690
Ziwei Dong: And, increase the speed of, like, onboarding different customer experience.

83
00:10:58.150 --> 00:10:59.650
Ziwei Dong: I see. Okay.

84
00:10:59.750 --> 00:11:10.499
Zhongzheng Xu: And then, so you said that you… at first, you tried a single LLM, and then it, naturally became a multi-agent system.

85
00:11:10.500 --> 00:11:11.030
Ziwei Dong: boom.

86
00:11:11.030 --> 00:11:20.200
Zhongzheng Xu: For the high-level structure, like, what agents are there going to be? What is, like, the role of each agent?

87
00:11:20.760 --> 00:11:25.870
Zhongzheng Xu: Did the high-level structure of your system also change over time?

88
00:11:26.640 --> 00:11:33.989
Ziwei Dong: It changes. So, yeah, there are a lot of, like, non-technical discussions.

89
00:11:35.670 --> 00:11:51.230
Ziwei Dong: Because in company, everybody wants to make sure their product is successful, so, the service provider or, like, customer experience provider from other teams, they want to put their service into Rufus.

90
00:11:52.110 --> 00:11:55.360
Ziwei Dong: So that they can benefit from the ruthless traffic.

91
00:11:55.700 --> 00:12:00.039
Ziwei Dong: So, people are fighting to send things in and out.

92
00:12:00.320 --> 00:12:07.429
Ziwei Dong: So every time, like, this sort of… I… this is some, like, non-technical discussions, like, independent contributor doesn't care.

93
00:12:07.430 --> 00:12:08.100
Zhongzheng Xu: Excellent.

94
00:12:08.100 --> 00:12:11.199
Ziwei Dong: But every time there's, like, updates, we need to update the system.

95
00:12:11.360 --> 00:12:20.689
Ziwei Dong: It's, it's, it's a… it's a challenging thing, but we built something… so there is one paper in last year's iClear, ICML.

96
00:12:20.910 --> 00:12:35.550
Ziwei Dong: I say MLI Clears, I forgot. It's like the oral paper. Oral paper, in a sense, it's like the best paper, sort of thing. So, it's called AFLO. I can share you the paper link later on. It's like a…

97
00:12:35.710 --> 00:12:36.960
Ziwei Dong: A floor.

98
00:12:41.590 --> 00:12:47.830
Ziwei Dong: It's like workflow generation. Automatic workflow generation, where you can have, like, reward modeling.

99
00:12:48.030 --> 00:13:03.030
Ziwei Dong: For example, when you delete or increase some feature of the… one of the sub-agents, and then use, build some pipeline, get inspired from the Aflow, and use… use it to let

100
00:13:03.920 --> 00:13:07.639
Ziwei Dong: The AFLO itself to automatically update each prompt scope.

101
00:13:07.780 --> 00:13:16.759
Ziwei Dong: Each prompts our responsibility, so that the updated multi-agent system can still function and they're compatible with each other.

102
00:13:17.030 --> 00:13:28.979
Ziwei Dong: Yeah, so this is, like, some research idea we tried. It somehow worked, but I… there's no guarantee that it's the best way to automation the entire process, because…

103
00:13:28.980 --> 00:13:30.150
Zhongzheng Xu: So… Okay.

104
00:13:31.110 --> 00:13:33.999
Zhongzheng Xu: So I've… I'm understanding this correctly, it's…

105
00:13:34.320 --> 00:13:38.810
Zhongzheng Xu: Generating prompt, generating even agents on the fly.

106
00:13:42.620 --> 00:13:45.159
Ziwei Dong: It's a modification, it's not generating.

107
00:13:45.160 --> 00:13:49.489
Zhongzheng Xu: Oh, it's a modif, okay. Yeah. It's modifying the current…

108
00:13:49.490 --> 00:13:55.510
Ziwei Dong: existing agents' scope? Because if you think about agents, essentially it's like a prompt.

109
00:13:55.910 --> 00:14:00.750
Ziwei Dong: prompt, connect those different tools, APIs, if necessary.

110
00:14:01.270 --> 00:14:02.080
Zhongzheng Xu: Okay.

111
00:14:02.080 --> 00:14:02.610
Ziwei Dong: Yeah.

112
00:14:02.610 --> 00:14:10.369
Zhongzheng Xu: So, again, I guess the things that you experimented the most,

113
00:14:11.060 --> 00:14:16.310
Zhongzheng Xu: For that project was the context management and then the system prompts.

114
00:14:17.300 --> 00:14:29.309
Ziwei Dong: So, it was the tool calling. Especially, we started this project with some, like, I won't be able to tell you the model, but it's, like, very early version of some model.

115
00:14:29.310 --> 00:14:30.300
Zhongzheng Xu: Oh.

116
00:14:30.300 --> 00:14:38.160
Ziwei Dong: We're trying a different type of the model from different companies. At the very beginning, like, the very… it's very challenging to have the two calling to…

117
00:14:38.490 --> 00:14:39.729
Ziwei Dong: To be accurate.

118
00:14:39.920 --> 00:14:47.969
Ziwei Dong: So it became a challenge. But later on, when the model is, like, getting better and better, because, like, so many models got released this year.

119
00:14:48.440 --> 00:14:48.800
Zhongzheng Xu: Yeah.

120
00:14:48.800 --> 00:14:53.969
Ziwei Dong: this problem, like, better. So, tool calling and the, like, the rack system,

121
00:14:54.420 --> 00:14:56.890
Ziwei Dong: Rich, are you familiar with RAC?

122
00:14:57.630 --> 00:14:58.330
Zhongzheng Xu: Yeah.

123
00:14:58.330 --> 00:15:08.640
Ziwei Dong: Yeah, yeah, so, the tool calling the rack was the very first challenge we… we have. But, like, the summarization, optimization, it's the problem that we'll later on have, yeah.

124
00:15:09.520 --> 00:15:12.599
Zhongzheng Xu: Okay. So…

125
00:15:13.690 --> 00:15:30.820
Zhongzheng Xu: Could you also tell me, how did you, like, how did you monitor your system, when, let's say you have a prototype, and then you want to make sure that it's working correctly, each agent is doing, like, the job that they should be doing, and then the output is also correct?

126
00:15:30.820 --> 00:15:40.919
Ziwei Dong: Yeah, so basically there's no way to do this monitoring, because it's interactive, like, people interact with it, and everything was on the fly. So there's no way to…

127
00:15:41.240 --> 00:15:44.279
Ziwei Dong: Be aware, oh, how my system is good or not.

128
00:15:44.350 --> 00:16:01.349
Ziwei Dong: But, you can still do sanity check, right? Before launching, you need to have some, like, offline evaluation to making sure what you're getting is correct, before you're sending to production. And this offline evaluation is some, like, data, like, different, like, employees.

129
00:16:01.380 --> 00:16:08.530
Ziwei Dong: to work on, it's, like, making sure it's, like, as close as the, like, actual, customer input.

130
00:16:08.590 --> 00:16:17.729
Ziwei Dong: The… so we're using this, like, the numbers generated by this offline dataset as, like, a proxy for how good it is.

131
00:16:18.270 --> 00:16:18.910
Zhongzheng Xu: Okay.

132
00:16:19.540 --> 00:16:20.810
Zhongzheng Xu: So…

133
00:16:21.120 --> 00:16:26.580
Zhongzheng Xu: I guess, yeah, that's just, like, more evaluation, making sure the system is behaving the way that it should.

134
00:16:26.580 --> 00:16:29.729
Ziwei Dong: Evaluation is a very important problem, but it's quite challenging, yeah.

135
00:16:29.950 --> 00:16:37.780
Zhongzheng Xu: Okay. Yeah, so I was actually asking more about, like, when you were developing,

136
00:16:38.310 --> 00:16:46.740
Zhongzheng Xu: Was there any, so, like, how did you check, let's say, the intermediate output of each agent?

137
00:16:48.600 --> 00:16:58.650
Ziwei Dong: This is more sort of an engineering problem. Like, the output of each agent will be put into some service, and this service will be connected to the next one.

138
00:16:58.730 --> 00:17:12.079
Ziwei Dong: sometimes the error happens, but the thing is, like, now, like, the models is, like, trying to be better, following the output, syntax, for example, JSON or MD.

139
00:17:12.079 --> 00:17:24.050
Ziwei Dong: Yeah. Like, different type of the format. So, it's really hard to define it's correct or incorrect, as long as the output, like, the format aligns with whatever the next agent is.

140
00:17:24.050 --> 00:17:24.839
Zhongzheng Xu: What else?

141
00:17:24.990 --> 00:17:29.599
Ziwei Dong: It will work. It's just a matter of, like, how good it works or how bad it works.

142
00:17:29.720 --> 00:17:33.639
Ziwei Dong: So, there is basically no arrows you can detect.

143
00:17:33.950 --> 00:17:42.869
Ziwei Dong: If it's there, even if there's error, it will be sent to retry it the next time, and the next turn… the next time, the error problem wouldn't be there.

144
00:17:43.060 --> 00:17:51.740
Zhongzheng Xu: Okay. So what was, like, the most common error or, like, bug that you ran into? I think you mentioned, tool calling.

145
00:17:52.350 --> 00:17:55.420
Zhongzheng Xu: And hallucinating at the beginning.

146
00:18:01.810 --> 00:18:04.879
Ziwei Dong: So I would still say it's a hallucination, yeah.

147
00:18:05.110 --> 00:18:05.930
Zhongzheng Xu: Hallucination.

148
00:18:05.930 --> 00:18:10.949
Ziwei Dong: Yeah, it's still the hallucination. It's… it's not even a bug. It wouldn't show you any bug.

149
00:18:10.950 --> 00:18:12.259
Zhongzheng Xu: It's not a bug.

150
00:18:12.260 --> 00:18:18.129
Ziwei Dong: It's just you realize what it says, like, sometimes it's… it's changing, especially under pressure.

151
00:18:18.410 --> 00:18:35.700
Ziwei Dong: For example, if you ask for some question that it does not know, you will say, oh, I don't know at the beginning, which is normal. But if you keep sending pressure, you must know you are, you're in, you are, like, whatever chatbot that you are so super, you must tell me this and that.

152
00:18:35.940 --> 00:18:41.409
Ziwei Dong: When, like, customers repeat this sort of, like, high-pressure queries, it starts to hallucinate.

153
00:18:42.860 --> 00:18:55.549
Zhongzheng Xu: So do you think that this hallucination problem… I mean, it can definitely be reduced by having a stronger model, but it doesn't come out every day. So just from an engineering perspective, how… like, what are some…

154
00:18:56.230 --> 00:19:03.119
Zhongzheng Xu: Actions that you can take to try to, like, minimize hallucination As much as possible.

155
00:19:04.210 --> 00:19:09.810
Ziwei Dong: Yeah, like, it really depends on how would you view this problem as a…

156
00:19:10.090 --> 00:19:18.510
Ziwei Dong: So, this problem… I think it can be solved or improved, I would say. I don't think it can be solved. It can be improved.

157
00:19:18.650 --> 00:19:36.750
Ziwei Dong: two ways that, like, for example, if you have, like, a small model or, like, open source model, you can fine-tune it, like, so that, like, DPO, GIPO, to making sure, it has, like, stronger regulation for the, actuality.

158
00:19:37.070 --> 00:19:44.209
Ziwei Dong: It will help, it will help. I tried. It helps, but it wouldn't help you to solve the problem 100%.

159
00:19:44.420 --> 00:19:54.580
Ziwei Dong: Second thing is, you can have some basic guardrails. For example, prevent model… so, it's like guardrail, it's more sort of like prevent model from saying some legal

160
00:19:55.780 --> 00:20:15.280
Ziwei Dong: legal requirements, right? But for the hallucination, I think there is some sort of question Gadriel can help you to… to do, but, like, Galleria wouldn't be able to solve 100% of the problem. This is, like, very… very much the biggest pain point, because if you think about, multi-agent system, it's actually a cascaded process.

161
00:20:15.300 --> 00:20:18.890
Ziwei Dong: Even though your model have, like, 99% of accuracy.

162
00:20:19.260 --> 00:20:27.400
Ziwei Dong: It looks great, but if you cascade the error rate at the end, it's, like, it's like 99 to the exponential of, like, 5 or 6.

163
00:20:27.510 --> 00:20:29.030
Ziwei Dong: It won't fail, yeah.

164
00:20:29.240 --> 00:20:29.890
Zhongzheng Xu: Yeah.

165
00:20:30.780 --> 00:20:39.219
Zhongzheng Xu: Right, okay. And then… so you also said that, The…

166
00:20:39.340 --> 00:20:49.000
Zhongzheng Xu: at industry, you first have, like, a working prototype, you present it to your manager. I wanted to ask, so, like.

167
00:20:49.310 --> 00:20:58.320
Zhongzheng Xu: at what point did you think that, okay, this prototype is pretty ready, this pipeline is pretty reliable, pretty consistent, I think…

168
00:20:58.340 --> 00:21:11.130
Zhongzheng Xu: it's okay now for me to share with my manager. Or even for production, like, what… like, how do you eventually decide that, okay, this, this pipeline or this multi-agent system can…

169
00:21:11.280 --> 00:21:14.080
Zhongzheng Xu: be actually.

170
00:21:14.220 --> 00:21:22.939
Ziwei Dong: Actually, this is not determined by me. So, like, prototype, it's, rather, like, I have more control over it, because prototype, I can…

171
00:21:23.620 --> 00:21:38.819
Ziwei Dong: I think as long as the functions I envision, like the 3 or 4 most important customer experience, I, if I'm able to, deliver that, I was confident to talk to my manager and my director, which is fine.

172
00:21:38.820 --> 00:21:39.370
Zhongzheng Xu: Okay.

173
00:21:39.370 --> 00:21:47.809
Ziwei Dong: But even, like, launching to production, it's some decision that, like, the director or VP, they need to make, so that's, sort of out of my control.

174
00:21:48.150 --> 00:21:49.759
Zhongzheng Xu: I see. I see.

175
00:21:50.200 --> 00:21:59.900
Zhongzheng Xu: Okay. And, okay, I have another question, which is, also just for developing.

176
00:22:00.390 --> 00:22:04.190
Zhongzheng Xu: the multi-agent system, do you think there's any…

177
00:22:04.310 --> 00:22:09.120
Zhongzheng Xu: Features, or, like, interface?

178
00:22:09.440 --> 00:22:11.969
Zhongzheng Xu: That could speed up that process.

179
00:22:12.090 --> 00:22:17.610
Zhongzheng Xu: Or what are some, like, features that's nice to have?

180
00:22:18.070 --> 00:22:32.179
Ziwei Dong: Yeah, this is a very good question. If you look back into the interactive machine learning domain, which is the problem space, I briefly touched it a little bit back in my PhD. So, later on, there is, like, I believe.

181
00:22:32.230 --> 00:22:49.920
Ziwei Dong: There… in deep learning, you need to have, like, different layers, like, fully cleansed layer, dense layer, whatever, polling layer. And there have been some people who did, like, interactive, machine learning, where they… you have, like, a UI, different layers come with, like, LEGO blocks.

182
00:22:49.920 --> 00:23:02.830
Ziwei Dong: You can drag them into the space, and then using a line to connect it, like, specify what is the input and output size, like, for example, 16, polling layer will be connected to,

183
00:23:02.830 --> 00:23:20.929
Ziwei Dong: like, 64, like, densely, whatever. So that's the, like, interactive way to do it. And then, machine will use translation to translate this sort of idea into implementations and help you to do the implement. So, like, building a machine learning, deep learning model became, like, an interactive way.

184
00:23:21.710 --> 00:23:23.709
Ziwei Dong: By the way, did you record a meeting?

185
00:23:24.210 --> 00:23:25.100
Zhongzheng Xu: Yeah, yeah.

186
00:23:25.100 --> 00:23:28.370
Ziwei Dong: Okay, okay, sounds good. Yeah, so…

187
00:23:28.620 --> 00:23:37.780
Ziwei Dong: That's actually a good idea for multi-agent, because multi-agent, basically, it comes with three things. First thing, like, multi-agent design.

188
00:23:37.780 --> 00:23:48.910
Ziwei Dong: Structure design, right? And then, in… other than structure design, within Orchestrator, you need to let Orchestrator know what are the other sub-agents with the definition.

189
00:23:48.970 --> 00:23:50.100
Ziwei Dong: That's the first thing.

190
00:23:50.190 --> 00:24:02.869
Ziwei Dong: Second thing, for the sub-agent, you need to specify this agent and that agent, what kind of external database you are… be able to access, because REG is, like, a very important thing.

191
00:24:02.870 --> 00:24:08.449
Zhongzheng Xu: Right now, because Model, there are a lot of domain knowledge that Model was not able to access.

192
00:24:08.450 --> 00:24:22.959
Ziwei Dong: For example, if you're in UMD, let's say you want to access your, like, UMD internal database for, like, student and employee information. That's something that the LLM doesn't know, because it's not pre-trained on that.

193
00:24:23.190 --> 00:24:30.509
Ziwei Dong: So, you need to… the second LEGO block is you need to let each sub-agent know

194
00:24:30.510 --> 00:24:43.259
Ziwei Dong: what kind of tools it can access to, and give the tool definition, give the tools… sorry, what kind of APIs, by API, you can actually call it a tool, because essentially it's tool calling, right?

195
00:24:43.440 --> 00:24:50.640
Ziwei Dong: So, for each tool, so what is each tool's definition? What is the exemplary input and output.

196
00:24:50.640 --> 00:24:52.500
Zhongzheng Xu: For each one. This thing you need to have.

197
00:24:53.300 --> 00:25:05.760
Ziwei Dong: And third thing, if you put everything into integrity, you need to be making sure that, like, the MCP and the connections between sub-agent and communication between sub-agents to the orchestrator

198
00:25:06.870 --> 00:25:15.650
Ziwei Dong: Yeah, this is something that I envision we can use, like, some sort of interactive UI to build this sort of system.

199
00:25:15.920 --> 00:25:18.499
Ziwei Dong: I don't think there's, like, too challenging things.

200
00:25:18.700 --> 00:25:24.830
Ziwei Dong: But it really depends on… The complexity you and their

201
00:25:25.160 --> 00:25:34.900
Ziwei Dong: Good, right? Yeah. But it definitely, improved from research perspective. It improves the accessibility, it improves the…

202
00:25:34.960 --> 00:25:51.570
Ziwei Dong: like, the generalizability and the, like, making sure that people who are not that technical can also be accessed to model aging. I don't see… so, I was thinking about this research idea a while back, and I did some, like, literature where nobody was doing it.

203
00:25:51.710 --> 00:25:54.650
Zhongzheng Xu: But it's, like, a very engineering-heavy project.

204
00:25:54.650 --> 00:25:59.489
Ziwei Dong: new myself working Amazon doesn't allow me to have a lot of bandwidth to work on it, yeah.

205
00:25:59.800 --> 00:26:02.850
Zhongzheng Xu: I think there's actually, some interfaces like that.

206
00:26:02.850 --> 00:26:03.230
Ziwei Dong: Oops.

207
00:26:03.310 --> 00:26:07.419
Zhongzheng Xu: I… I can share a screen real quick.

208
00:26:07.950 --> 00:26:16.040
Zhongzheng Xu: I know people have been trying it, there's also a couple tools available out there, but I think the problem

209
00:26:16.390 --> 00:26:19.310
Zhongzheng Xu: With those tools is that they don't… hmm…

210
00:26:21.520 --> 00:26:23.680
Zhongzheng Xu: So this is one of the tools.

211
00:26:24.100 --> 00:26:25.880
Zhongzheng Xu: They have…

212
00:26:25.880 --> 00:26:27.699
Ziwei Dong: It's already there. Way.

213
00:26:27.700 --> 00:26:36.190
Zhongzheng Xu: Started there, yeah, yeah, they have, like, agents… You can also define, like, the tools…

214
00:26:36.830 --> 00:26:40.870
Zhongzheng Xu: Also, RAC Database, I think.

215
00:26:41.390 --> 00:26:44.290
Ziwei Dong: I see, yes. I see, okay.

216
00:26:44.570 --> 00:26:45.360
Ziwei Dong: Yeah.

217
00:26:45.900 --> 00:26:48.560
Zhongzheng Xu: But it's,

218
00:26:49.610 --> 00:26:58.909
Zhongzheng Xu: I don't know, from what I have been… from my experience, or not my experience, but, like, from the interviews I have done so far, I feel like

219
00:27:00.760 --> 00:27:06.759
Zhongzheng Xu: not many people are using it. I'm not sure, the reason why.

220
00:27:06.760 --> 00:27:10.839
Ziwei Dong: So, yeah, I can tell you the reason. So…

221
00:27:11.020 --> 00:27:14.179
Ziwei Dong: I'll use one example, prompt tuning.

222
00:27:15.300 --> 00:27:17.250
Ziwei Dong: Very easy and straightforward thing, right?

223
00:27:17.610 --> 00:27:17.970
Zhongzheng Xu: Yeah.

224
00:27:17.970 --> 00:27:26.219
Ziwei Dong: very beginning, like, the, like, engineers and, like, the PMs in Amazon, they're not there to tune a prompt.

225
00:27:27.120 --> 00:27:29.199
Ziwei Dong: They think it's, like, a very technical thing.

226
00:27:29.440 --> 00:27:34.549
Ziwei Dong: So they send it to scientists, but scientists don't want to tune a prompt. It's like, there's no sense for a code there.

227
00:27:35.040 --> 00:27:47.970
Ziwei Dong: So there is, like, a misunderstanding, or, like, the learning curve, where people start to think, oh, aging, like, super complicated, like, a lot of things need to be done. Anything… mistake made can be easily propagated.

228
00:27:48.530 --> 00:28:03.160
Ziwei Dong: So, I'm viewing this as, like, one of the reasons for why not a lot of people are using it, because, first of all, like, people who work on agents, engineers and scientists, they don't need this tool. They know how to make…

229
00:28:03.160 --> 00:28:04.460
Zhongzheng Xu: You can just use LendChain.

230
00:28:04.460 --> 00:28:07.770
Ziwei Dong: Yeah, nothing is needed by PMs.

231
00:28:09.030 --> 00:28:18.389
Ziwei Dong: PMs and designers, UX designers. But those people still intimidated by this, like, oh, this, like, complicated thing is, like, very technical, I cannot use it.

232
00:28:18.720 --> 00:28:28.250
Zhongzheng Xu: And, yeah. And if you're just designing or, like, envisioning, then you don't need something that actually works. You can just use a PowerPoint, right?

233
00:28:30.150 --> 00:28:40.650
Zhongzheng Xu: Yeah, I also had the same thought. I think it's just kind of awkward. I feel like it's not easy enough for people who don't have any experience to build.

234
00:28:40.750 --> 00:28:42.280
Ziwei Dong: A working pipeline.

235
00:28:42.280 --> 00:28:46.139
Zhongzheng Xu: But it's also, like, Kind of a toy to actual engineers.

236
00:28:46.440 --> 00:28:48.600
Ziwei Dong: yeah, I agree, I agree.

237
00:28:49.200 --> 00:29:00.640
Zhongzheng Xu: Okay. And then… So… We're… Trying to locate the question.

238
00:29:01.700 --> 00:29:04.470
Zhongzheng Xu: Okay, and then…

239
00:29:05.330 --> 00:29:17.430
Zhongzheng Xu: I'm gonna go back to being a little bit more general. So, for what type of problems you think a multi-agent system worked the best? I think you already talked about

240
00:29:17.630 --> 00:29:19.660
Zhongzheng Xu: About it, a little bit.

241
00:29:19.660 --> 00:29:21.840
Ziwei Dong: I see. So, hmm…

242
00:29:22.910 --> 00:29:31.169
Ziwei Dong: I… to be honest, I still don't believe multi-agent system can be that reliable for very complicated problems.

243
00:29:31.340 --> 00:29:42.630
Ziwei Dong: for example, like, a lot of, like, agents need to back and forth send information, it's an iteration, so this thing, I don't think it's the best use case. I believe it's the use case where

244
00:29:43.040 --> 00:29:48.899
Ziwei Dong: So, abstract… my idea here.

245
00:29:49.230 --> 00:29:53.390
Ziwei Dong: I believe it's, like, quite complicated work.

246
00:29:53.900 --> 00:30:05.810
Ziwei Dong: That, can be done by single agent, but when be done by a single agent, you need to take some trade-off, either hallucination, either latency, or either usability.

247
00:30:06.350 --> 00:30:12.250
Ziwei Dong: So that… I think multi-aging system is a way to scale up

248
00:30:12.760 --> 00:30:20.740
Ziwei Dong: But it's functionality-wise, I still think, like, the multi-agent system

249
00:30:20.980 --> 00:30:40.089
Ziwei Dong: It's just as good as a single agent system, if you want it to do something. It's not like a superhero or superpower who, like, could, like, be advanced on a lot of, like, performance-wise. It's just, like, a way to scale up, and to split the workload so that model will less hallucinate.

250
00:30:40.780 --> 00:30:41.560
Zhongzheng Xu: I see.

251
00:30:42.590 --> 00:30:51.779
Zhongzheng Xu: Okay, that was actually the last question from what I've prepared, but before we end, I actually have a very specific question. So for the system prompts.

252
00:30:54.140 --> 00:31:06.469
Zhongzheng Xu: when you're developing, are they, did you… like, where do you… how, like, how did you edit it? Did you keep it just in the, like, code editor as a long… super long string, or did you have it somewhere else?

253
00:31:06.630 --> 00:31:15.040
Ziwei Dong: Oh, no, it's like the Python console, like VS Code, Python, Python file. It's like prompt equals to comma,

254
00:31:15.200 --> 00:31:18.059
Ziwei Dong: Like, we're betting a coma, it's, like, a lot of prompts, like…

255
00:31:18.060 --> 00:31:21.129
Zhongzheng Xu: So, it's just a super long string in Python.

256
00:31:21.820 --> 00:31:24.780
Zhongzheng Xu: Okay. Okay.

257
00:31:24.920 --> 00:31:35.490
Zhongzheng Xu: So, the reason why I ask that is because, I have interviewed, probably, like, 7, 8 people now, and then, one of the problems

258
00:31:35.810 --> 00:31:38.900
Zhongzheng Xu: The most common problem is probably…

259
00:31:39.070 --> 00:31:44.830
Zhongzheng Xu: writing system prompts. And then… So…

260
00:31:45.200 --> 00:31:48.840
Zhongzheng Xu: my mentor and I are thinking about

261
00:31:49.520 --> 00:32:00.939
Zhongzheng Xu: doing something about it, and so, I actually interviewed another person, she interned at Amazon, and then she… she had this 3-month internship.

262
00:32:02.120 --> 00:32:12.089
Zhongzheng Xu: to build, like, some sort of multi-agent system, but she spent almost 2 months just writing system prompts. So…

263
00:32:12.440 --> 00:32:14.630
Zhongzheng Xu: It was… it was very…

264
00:32:14.940 --> 00:32:29.800
Zhongzheng Xu: tedious, because, she was just, like, traveling and erring. She would have, like, a prompt, and then she would run the system, just wait for, like, unexpected behavior to occur, and then manually include that

265
00:32:30.070 --> 00:32:39.999
Zhongzheng Xu: unexpected behavior into the problem. Be like, oh, do not do this, do not do that. But then, they eventually turned into this framework

266
00:32:40.500 --> 00:32:42.229
Zhongzheng Xu: I don't know if you have heard…

267
00:32:42.490 --> 00:32:43.340
Ziwei Dong: Auto prompt.

268
00:32:45.360 --> 00:32:48.170
Zhongzheng Xu: It's… it uses…

269
00:32:48.460 --> 00:33:07.909
Zhongzheng Xu: It's a framework, and it uses some prompt optimization technique. So basically, instead of writing system prompt yourself, you just define the input and output, and you provide some in-context learning examples, and then, it tries to determine the best route for that set of input and output.

270
00:33:09.200 --> 00:33:14.099
Ziwei Dong: Yeah, I think, for example, Claude itself has, like, the prompt optimization.

271
00:33:14.230 --> 00:33:15.230
Zhongzheng Xu: Yeah.

272
00:33:15.680 --> 00:33:16.280
Ziwei Dong: Yeah.

273
00:33:17.190 --> 00:33:22.150
Zhongzheng Xu: So we're currently brainstorming, but we feel like

274
00:33:22.320 --> 00:33:27.300
Zhongzheng Xu: We wanted to do something, maybe like a visual…

275
00:33:27.330 --> 00:33:46.439
Zhongzheng Xu: something visual about, editing your prompt, because, at least I think that, so system prompts for multi-agent system, they usually follow some structure. They always have some, inputs and outputs and, like you said, like, tools, tools definitions, also the context.

276
00:33:46.600 --> 00:33:57.010
Zhongzheng Xu: So we're thinking… maybe, maybe do something about that. For example, like, visualize the structure.

277
00:33:58.650 --> 00:34:00.180
Zhongzheng Xu: Inputs and outputs.

278
00:34:01.230 --> 00:34:02.380
Zhongzheng Xu: Things like that.

279
00:34:07.020 --> 00:34:26.140
Ziwei Dong: Yeah, so I, I think… I imagine there something can be done over here, it's like an interpretation tool, in the sense that, for example, it's not building a multi-agent system, it's, it's more so understanding multi-agent system, and the debugging and a problem, problem shooting. For example, if I gave you, like, super long multi-system pro…

280
00:34:26.750 --> 00:34:38.630
Ziwei Dong: multi-agent system. Can you give me a tool so that this tool can help me, visualize in a diagram that… how does… what is the workflow of this multi-agent system?

281
00:34:38.800 --> 00:34:43.820
Ziwei Dong: And what is the input-output of this multi-agent system? And then tell me, what is the gap?

282
00:34:44.040 --> 00:34:53.569
Ziwei Dong: Gap, meaning there is some functionality that orchestrator thinks the sub-agent can be done, but the sub-agent itself, or, like, the collaboration itself, has some gap.

283
00:34:53.889 --> 00:35:12.720
Ziwei Dong: So, this tool can be… help to diagnose the problem, and help for the future refinement. It's also, like, a tool that helps with, like, interpretation and the, like, transparency, improve the, like, the multi-aging transparency. It will be useful, yeah.

284
00:35:14.230 --> 00:35:24.620
Zhongzheng Xu: so, I'm not sure… If this is… But I think, AWS…

285
00:35:26.070 --> 00:35:27.250
Ziwei Dong: Already has it.

286
00:35:27.250 --> 00:35:32.460
Zhongzheng Xu: Already has it, it's called… AWS Observability.

287
00:35:34.250 --> 00:35:35.940
Ziwei Dong: observability.

288
00:35:40.480 --> 00:35:42.800
Ziwei Dong: Observability multi-agent.

289
00:35:44.740 --> 00:35:46.160
Zhongzheng Xu: Aging…

290
00:35:46.870 --> 00:35:47.750
Ziwei Dong: Really?

291
00:35:51.440 --> 00:35:52.770
Zhongzheng Xu: I'm not sure if it's…

292
00:35:53.090 --> 00:35:58.439
Ziwei Dong: Skywalk Aging Corps of the Office of Observability.

293
00:36:04.780 --> 00:36:09.600
Ziwei Dong: It's called AWS, Bedrock Aging Core Observability.

294
00:36:09.600 --> 00:36:13.239
Zhongzheng Xu: Yeah, yeah. Provides detailed visualization of the aging workflow.

295
00:36:16.080 --> 00:36:18.840
Ziwei Dong: Yeah, yeah, it's already provided.

296
00:36:22.190 --> 00:36:22.880
Ziwei Dong: Yeah.

297
00:36:22.880 --> 00:36:29.860
Zhongzheng Xu: The reason why I know this is I took, AWS AI Practitioner, certificate.

298
00:36:30.110 --> 00:36:34.430
Ziwei Dong: Okay, yeah. Yeah, the aging world is, like, developing too fast, yeah.

299
00:36:34.430 --> 00:36:36.180
Zhongzheng Xu: Yeah, yeah.

300
00:36:36.730 --> 00:36:40.479
Zhongzheng Xu: But okay, we can end, it's…

301
00:36:40.700 --> 00:36:46.099
Zhongzheng Xu: I think it's about time. But yeah, just… I'll stop recording.

